{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57226901",
   "metadata": {},
   "source": [
    "# Transforming the PDF files into vector database  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c8d88",
   "metadata": {},
   "source": [
    "# 1. Initial Setup\n",
    "This setup includes loading environment variables from a `.env` file, setting the required environment variables, and importing the necessary modules for further processing. It ensures that the code has access to the required APIs and functions for the subsequent tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "06fc759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial set up\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "# Load the variables from .env file and set the API key (or user may manually set the API key)\n",
    "load_dotenv()  # This loads the variables from .env (not part of repo)\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Import the necessary modules\n",
    "from langchain import hub\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableParallel # for RAG with source\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from IPython.display import display, Markdown, Latex\n",
    "import glob\n",
    "import chromadb\n",
    "## \n",
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "# from langchain_community.document_loaders import PyMuPDFLoader ## not used\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.document_loaders import PDFMinerLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "35630ca8-a707-4445-b8a2-661fe3312d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initial variable setup\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "db_directory = \"./data/chroma\"\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0) # context window size 16k for GPT 3.5 Turbo    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04673e4",
   "metadata": {},
   "source": [
    "# 2. Load PDF Files and Convert to a Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3c3b91d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load and extract text from PDFs in a folder\n",
    "def get_file_name(source_path):\n",
    "    return source_path.split('/')[-1]\n",
    "\n",
    "def load_pdfs_from_folder(folder_path):\n",
    "    # Get a list of PDF files in the specified folder\n",
    "    pdf_files = glob.glob(f\"{folder_path}/*.pdf\")\n",
    "    docs = []\n",
    "    for pdf_file in pdf_files:\n",
    "        file_name = get_file_name(pdf_file)\n",
    "        \n",
    "        # Load the PDF file using the PyPDFLoader\n",
    "        #loader = PyPDFLoader(pdf_file)\n",
    "        loader = PDFMinerLoader(pdf_file, concatenate_pages=True) \n",
    "        loaded_docs = loader.load()\n",
    "        \n",
    "        for doc in loaded_docs:\n",
    "            doc.metadata['source'] = file_name\n",
    "        \n",
    "        docs.extend(loaded_docs)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b938f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Original Chunk\n",
    "############################################################################\n",
    "collection_list=[\n",
    "    \"ASOP_life\",\n",
    "    \"Bermuda\",\n",
    "    \"CFT\",\n",
    "    \"VM21\",\n",
    "    \"VM22\",\n",
    "    \"Asset\",\n",
    "    \"IFRS17\"\n",
    "]\n",
    "\n",
    "#collection_list=[\"CFT\"]\n",
    "\n",
    "for collection_name in collection_list:\n",
    "    # Example folder path\n",
    "    folder_path = './data/'+collection_name\n",
    "\n",
    "    # Call the function to load and extract text from PDFs in the specified folder\n",
    "    docs = load_pdfs_from_folder(folder_path)\n",
    "    \n",
    "    # Create a text splitter object with specified parameters\n",
    "    # text_splitter = RecursiveCharacterTextSplitter(\n",
    "    #     chunk_size=1000, # 1000 splits a page into roughly 3 chunks\n",
    "    #     chunk_overlap=200,\n",
    "    #     length_function=len,)\n",
    "\n",
    "    # Split the documents into chunks using the text splitter\n",
    "    #splits = text_splitter.split_documents(docs)\n",
    "    \n",
    "    text_splitter = SemanticChunker(OpenAIEmbeddings())\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    # Create a Chroma vector database from the document splits, using OpenAIEmbeddings for embedding\n",
    "    vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                        embedding=embeddings_model, \n",
    "                                        persist_directory=db_directory,collection_name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f9d12526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "collection_name=\"Bermuda\"\n",
    "\n",
    "# Example folder path\n",
    "folder_path = './data/'+collection_name\n",
    "#file_name = \"201709 Asset_Adequacy_PracticeNote.pdf\"\n",
    "\n",
    "def load_pdfs_from_folder_test(folder_path):\n",
    "    # Get a list of PDF files in the specified folder\n",
    "    pdf_files = glob.glob(f\"{folder_path}/*.pdf\")\n",
    "    docs = []\n",
    "    for pdf_file in pdf_files:\n",
    "        file_name = get_file_name(pdf_file)\n",
    "        \n",
    "        # Load the PDF file using the PyPDFLoader\n",
    "        #loader = PyPDFLoader(pdf_file)\n",
    "        #loader = PyPDFium2Loader(pdf_file) \n",
    "        # PyPDFium2Loader is known to be faster than PyPDFLoader\n",
    "        #loader = PyMuPDFLoader(pdf_file) \n",
    "        # PyMuPDFLoader is known to be general purpose, rich metadata\n",
    "        loader = PDFMinerLoader(pdf_file, concatenate_pages=True) \n",
    "        loaded_docs = loader.load()\n",
    "        \n",
    "        for doc in loaded_docs:\n",
    "            doc.metadata['source'] = file_name\n",
    "        \n",
    "        docs.extend(loaded_docs)\n",
    "    return docs\n",
    "\n",
    "docs = load_pdfs_from_folder_test(folder_path)\n",
    "len(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33c4f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f93db41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SemanticChunker(OpenAIEmbeddings())\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "47405d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Specifics of the method are provided below. 7. The  Authority has  developed  a  set  of  interest  rate  scenarios  that  have  been  calibrated \\nusing an economic scenario generator to develop deviations that are approximately one \\nstandard deviation away from  the  mean  so  as  to  target  events  that  may reasonably be \\nexpected  to  occur. More  extreme  scenarios  would  be  captured  in  the  capital \\nrequirement. These scenarios cover a number of  different  interest  rate  patterns  (such \\nas  increasing,  decreasing,  increasing  and  decreasing, twists where the long and short \\nterm rates behave differently, etc.)  The specific scenarios are as follows: \\n\\na. All  rates  decrease  annually  to  total  decrease  of  1.5%  in  tenth  year;  unchanged \\n\\nthereafter. b. All  rates  increase  annually  to  total  increase  of  1.5%  in  tenth  year;  unchanged \\n\\nthereafter. c. All  rates  decrease  annually  to  total  decrease  of  1.5%  in  fifth  year  then  back  up \\n\\nagain by tenth year. d. All rates increase annually to total increase of 1.5% in fifth year then back down \\n\\nagain by tenth year. e. Decrease  with  positive  twist  to  the  following  net  change  after  ten  years  (interpolate \\n\\nfor other durations): \\n\\ni. Year 1 spot rate -1.5% \\nii. Year 10 spot rate -1.0% \\niii. Year 30 spot rate -0.5% \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cf. Decrease  with  negative  twist  to  the  following  net  change  after  for  ten  years \\n\\n(interpolate for other durations): \\ni. Year 1 spot rate -0.5% \\nii. Year 10 spot rate -1.0% \\niii. Year 30 spot rate -1.5% \\n\\ng. Increase  with  positive  twist  to  the  following  net  change  after  ten  years  (interpolate \\n\\nfor other durations): \\n\\ni. Year 1 spot rate +0.5% \\nii. Year 10 spot rate +1.0% \\niii. Year 30 spot rate +1.5% \\n\\nh. Increase with negative twist to the following net change after for ten years (interpolate \\n\\nfor other durations): \\n\\ni. Year 1 spot rate +1.5% \\nii. Year 10 spot rate +1.0% \\niii. Year 30 spot rate +0.5% \\n\\n8. The  reinvestment  assumptions  will  reflect  the  company’s  investment  guidelines  and \\nwill be considered as part of the Approved Actuary Opinion and also be disclosed in an \\nActuarial  Memorandum  to  accompany  the  submission. It  is  anticipated  that  the \\nActuarial  Memorandum  will  incorporate  a  number  of  other  pieces  of  information, \\nincluding  an  assessment  of  the  extent  of  asset  liability  matching  in  the  portfolio. Detailed content of the Actuarial Memorandum will be developed, in consultation with \\nindustry, in the coming months. 9.', metadata={'source': 'Determination of Discount Rates for Economic Balance Sheet.pdf'})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[312]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eb885be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=embeddings_model, \n",
    "                                    persist_directory=db_directory,collection_name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "48684638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IFRS17\n"
     ]
    }
   ],
   "source": [
    "print(collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46105ba",
   "metadata": {},
   "source": [
    "# 3. Retrieve from the Vector DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ebf7693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FYI - not used\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e9abd0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a Chroma vector database with specified parameters\n",
    "vectorstore = Chroma(embedding_function=embeddings_model, \n",
    "                     persist_directory=db_directory,\n",
    "                     collection_name=\"Bermuda\")\n",
    "## a user may choose different collection name from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9744b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve and RAG chain\n",
    "# Create a retriever using the vector database as the search source\n",
    "# You may choose a specific document to filter the search\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", \n",
    "                                     search_kwargs={\n",
    "                                        'k': 6, \n",
    "                                        'lambda_mult': 0.5,\n",
    "                                        # 'filter': {'source': '201611-Guidance-Notes-for-Commercial-Insurers-and-Groups-Statutory-Reporting-Regime-30-Nov-2016.pdf'}\n",
    "                                        }\n",
    "                                    ) \n",
    "# Use MMR (Maximum Marginal Relevance) to find a set of documents that are both similar to the input query and diverse among themselves\n",
    "# Increase the number of documents to get, and increase diversity (lambda mult 0.5 being default, 0 being the most diverse, 1 being the least)\n",
    "\n",
    "# Load the RAG (Retrieval-Augmented Generation) prompt\n",
    "#prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "qa_system_prompt = \"\"\"You are a helpful assistant to help actuaries with question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "ASOP or asop means Actuarial Standards of Practice. \\\n",
    "CFT means Cash Flow Testing. AAT means Asset Adequacy Testing. \\\n",
    "BMA means Bermuda Monetary Authority. \\\n",
    "SBA means scenario-based approach. BEL means best estimate liabilities.\\\n",
    "After you answer, provide the sources you used to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "\n",
    "{context}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define a function to format the documents with their sources and pages\n",
    "def format_docs_with_sources(docs):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    #sources_pages = \"\\n\".join(f\"{doc.metadata['source']} (Page {doc.metadata['page'] + 1})\" for doc in docs)\n",
    "    sources_pages = \"\\n\".join(f\"{doc.metadata['source']})\" for doc in docs)\n",
    "    # Added 1 to the page number assuming 'page' starts at 0 and we want to present it in a user-friendly way\n",
    "\n",
    "    return f\"Documents:\\n{formatted_docs}\\n\\nSources and Pages:\\n{sources_pages}\"\n",
    "\n",
    "# Create a RAG chain using the formatted documents as the context\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs_with_sources(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Create a parallel chain for retrieving and generating answers\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9243e34a",
   "metadata": {},
   "source": [
    "# 4. Generate Q&A Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1ceedb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output():\n",
    "    # Prompt the user for a question on ASOP\n",
    "    usr_input = input(\"What is your question on ASOP?: \")\n",
    "\n",
    "    # Invoke the RAG chain with the user input as the question\n",
    "    output = rag_chain_with_source.invoke(usr_input)\n",
    "\n",
    "    # Generate the Markdown output with the question, answer, and context\n",
    "    markdown_output = \"### Question\\n{}\\n\\n### Answer\\n{}\\n\\n### Context\\n\".format(output['question'], output['answer'])\n",
    "\n",
    "    last_page_content = None  # Variable to store the last page content\n",
    "    i = 1 # Source indicator\n",
    "\n",
    "    # Iterate over the context documents to format and include them in the output\n",
    "    for doc in output['context']:\n",
    "        current_page_content = doc.page_content.replace('\\n', '  \\n')  # Get the current page content\n",
    "        \n",
    "        # Check if the current content is different from the last one\n",
    "        if current_page_content != last_page_content:\n",
    "            #markdown_output += \"- **Source {}**: {}, page {}:\\n\\n{}\\n\".format(i, doc.metadata['source'], doc.metadata['page'], current_page_content)\n",
    "            markdown_output += \"- **Source {}**: {}:\\n\\n{}\\n\".format(i, doc.metadata['source'], current_page_content)\n",
    "            i = i + 1\n",
    "        last_page_content = current_page_content  # Update the last page content\n",
    "    \n",
    "    # Display the Markdown output\n",
    "    display(Markdown(markdown_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d54daa6",
   "metadata": {},
   "source": [
    "# Example questions related to ASOPs\n",
    "- explain ASOP No. 14\n",
    "- How are expenses relfected in cash flow testing based on ASOP No. 22?\n",
    "- What is catastrophe risk?\n",
    "- When do I update assumptions?\n",
    "- What should I do when I do not have credible data to develop non-economic assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "36183436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Question\n",
       "explain eight interest rate scenarios used for Scenario-based approach.\n",
       "\n",
       "### Answer\n",
       "The eight interest rate scenarios used for the Scenario-based approach are as follows:\n",
       "\n",
       "1. All rates decrease annually to a total decrease of 1.5% in the tenth year, unchanged thereafter.\n",
       "2. All rates increase annually to a total increase of 1.5% in the tenth year, unchanged thereafter.\n",
       "3. All rates decrease annually to a total decrease of 1.5% in the fifth year, then back up again by the tenth year.\n",
       "4. All rates increase annually to a total increase of 1.5% in the fifth year, then back down again by the tenth year.\n",
       "5. Decrease with a positive twist to the following net change after ten years (interpolate for other durations): -1.5%.\n",
       "   - Year 1 spot rate\n",
       "   - Year 10 spot rate\n",
       "   - Year 30 spot rate\n",
       "6. Decrease with a negative twist to the following net change after ten years (interpolate for other durations): -0.5%.\n",
       "   - Year 1 spot rate\n",
       "   - Year 10 spot rate\n",
       "   - Year 30 spot rate\n",
       "7. Increase with a positive twist to the following net change after ten years.\n",
       "   - Year 1 spot rate: +0.5%\n",
       "   - Year 10 spot rate: +1.0%\n",
       "   - Year 30 spot rate: +1.5%\n",
       "8. Increase with a negative twist to the following net change after ten years.\n",
       "   - Year 1 spot rate: +1.5%\n",
       "   - Year 10 spot rate: +1.0%\n",
       "   - Year 30 spot rate: +0.5%\n",
       "\n",
       "These scenarios are designed to reflect different interest rate patterns and behaviors, allowing for a comprehensive assessment of interest rate risk under the Scenario-based approach.\n",
       "\n",
       "Sources:\n",
       "BMA 202312-Supervision-and-Regulation-of-Private-Equity-Insurers.pdf\n",
       "\n",
       "### Context\n",
       "- **Source 1**: 201611-Guidance-Notes-for-Commercial-Insurers-and-Groups-Statutory-Reporting-Regime-30-Nov-2016.pdf:\n",
       "\n",
       "Specifics of the method (including calculation details) are provided below. 257. The Authority has developed a set of interest rate scenarios to be used in this method. a. These   scenarios   will   cover   a   number   of   different   interest   patterns   (such   as   \n",
       "increasing  decreasing,  increasing  and  decreasing,  twists  where  the  long  and  short   \n",
       "term rates behave differently etc.)   \n",
       "  \n",
       "b. These  scenarios  have  been  calibrated  using  an  economic  scenario  generator  such   \n",
       "that  the  deviations  are  approximately  one  standard  deviation  away  from  the  mean   \n",
       "so  as  target  events  that  may  reasonably  be  expected  to  occur. More  extreme   \n",
       "scenarios would be reflected in the capital requirement. c.\n",
       "- **Source 2**: 2023-12-20-11-08-13-2023-Year-End-Long-Term-Instructions-Handbook.pdf:\n",
       "\n",
       "and the base scenario under the scenario -based approach, according to the formula   \n",
       "specified in the Prudential Rules.    \n",
       "C28.1g  As a simplification companies using the scenario -based approach may calculate the capital   \n",
       "charge for interest rate risk (before the application of offset) based on shocks to the   \n",
       "balance sheet as if the base scenario had been applied. In this case the offse t is to be   \n",
       "calculated as the difference between the ‘worst ’ scenario and the base scenario before the   \n",
       "application of shocks.\n",
       "- **Source 3**: 2023-12-20-13-15-07-2023-Year-End-Stress-and-Scenario-Instructions-for-Class-C-D--E.pdf:\n",
       "\n",
       "R8. Inflation   \n",
       "and Monetary   \n",
       "Policy Risk   \n",
       "  \n",
       "Inflation risk stems from the general uncertainty of prices. Higher than expected inflation decreases the real yield on loans and debts while it may increase   \n",
       "the value of indemnities, claims and expenses. Simulate a scenario similar to the 2022   \n",
       "inflationary scenario. The (re)insurer should apply each inflation scenario for three years assuming no initial action to   \n",
       "curb inflation from central banks. In year four, the central bank changes stance and increases   \n",
       "rates to restore the current real interest rate. From year five onwards, inflation and interest rates   \n",
       "return to current levels. Scenario   \n",
       "  \n",
       "Moderate   \n",
       "Inflation   \n",
       "Severe Inflation   \n",
       "  \n",
       "Change in   \n",
       "inflation   \n",
       "rate (Y1)   \n",
       "  \n",
       "Change in   \n",
       "inflation   \n",
       "rate (Y2)   \n",
       "  \n",
       "+5.0%   \n",
       "  \n",
       "+5.0%   \n",
       "  \n",
       "Change in   \n",
       "inflation   \n",
       "rate (Y3)   \n",
       "+5.0%   \n",
       "  \n",
       "Change in   \n",
       "inflation and   \n",
       "interest rate (Y4)   \n",
       "+5.0%   \n",
       "  \n",
       "+10.0%   \n",
       "  \n",
       "+10.0%   \n",
       "  \n",
       "+10.0%   \n",
       "  \n",
       "+10.0%   \n",
       "  \n",
       "To clarify, these stresses should be additively applied to the prevailing annual inflation/interest   \n",
       "rate assumption used in valuing asset and liabilities (e.g., if the prevailing assumption is 3% p.a. then the moderate stressed assumption should be 8% p.a. for the first four years before returning   \n",
       "to 3% p.a.). Scenario   \n",
       "Deflation scenario   \n",
       "  \n",
       "Stressed inflation rate   \n",
       "-1.0%   \n",
       "  \n",
       "This stress should replace the prevailing annual inflation rate assumption used in valuing assets   \n",
       "and liabilities (e.g., if the prevailing assumption is 3% p.a. then the deflation scenario   \n",
       "assumption should be -1% p.a., i.e., a 4% p.a. reduction in expectations). The interest rate   \n",
       "assumption in year four should mirror the change in the inflation rate (i.e., -4% p.a. in the   \n",
       "previous example).\n",
       "- **Source 4**: BMA 202312-Supervision-and-Regulation-of-Private-Equity-Insurers.pdf:\n",
       "\n",
       "interest rate scenarios, i.e., the SBA, again by design, accepts that there is no single truth about the   \n",
       "future of interest rates (hence discount curves) and reflects this uncertainty and its potential impact   \n",
       "on asset  and liability cashflows in the BEL calculation. Where a mismatch exists, because of asset and   \n",
       "liability cashflow dynamics, the SBA assigns an explicit cost by picking the worst of the eight scenarios   \n",
       "to determine the BEL. Over the past two years, Bermuda insurers using the SBA have withstood even   \n",
       "higher interest rate shocks than  those  shown in the illustrative example above.    \n",
       "   \n",
       "As part of its supervisory process, the Authority carries out several assessments, which include   \n",
       "requiring insurers to demonstrate the degree of matching quantitatively and qualitatively for the   \n",
       "insurer’s existing asset and liability portfolios for which the SBA is used or proposed to be used.\n",
       "- **Source 5**: 2023-07-28-16-11-59-Consultation-Paper---Proposed-Enhancements-to-the-Regulatory-Regime-and-Fees-for-Commercial-Insurers.pdf:\n",
       "\n",
       "assessed over different time horizons with a focus on those horizons over which particular   \n",
       "risks are expected to arise. Insurer -specific and market -wide scen arios should be   \n",
       "considered , including their combinations. The scenarios should cover fast -moving and   \n",
       "more sustained scenarios where the insurer’s liquidity position deteriorates slowly. Tests   \n",
       "should also be carried out to test the insurer’s liquidity break ing point (i.e., liquidity reverse   \n",
       "stress tests ).\n",
       "- **Source 6**: 201611-Guidance-Notes-for-Commercial-Insurers-and-Groups-Statutory-Reporting-Regime-30-Nov-2016.pdf:\n",
       "\n",
       "The specific scenarios are as follows:   \n",
       "  \n",
       "i. All  rates  decrease  annually  to  total  decrease  of  1.5%  in  tenth   year;   \n",
       "unchanged thereafter. ii. All   rates   increase   annually   to   total   increase   of   1.5%   in   tenth   year;   \n",
       "  \n",
       "unchanged thereafter. iii. All  rates  decrease  annually  to  total  decrease  of  1.5%  in  fifth  year,  then   \n",
       "  \n",
       "back up again by tenth year. iv. All rates increase annually to total increase of 1.5% in fifth year, then back   \n",
       "  \n",
       "down again by tenth year. v. Decrease  with  positive  twist  to  the  following  net  change  after  ten  years   \n",
       "  \n",
       "(interpolate for other durations):    \n",
       "  \n",
       "-1.5%    \n",
       "i. Year 1 spot rate   \n",
       "ii. Year 10 spot rate   -1.0%    \n",
       "iii. Year 30 spot rate   -0.5%   \n",
       "  \n",
       "vi. Decrease with negative twist to the following net change after for ten years   \n",
       "  \n",
       "(interpolate for other durations):    \n",
       "  \n",
       "-0.5%    \n",
       "i. Year 1 spot rate   \n",
       "ii. Year 10 spot rate   -1.0%    \n",
       "iii. Year 30 spot rate   -1.5%   \n",
       "  \n",
       "45   \n",
       "  \n",
       "   \n",
       "   \n",
       "   \n",
       "   \n",
       "   \n",
       "   \n",
       "   \n",
       "   \n",
       "   \n",
       "    \n",
       "   \n",
       "   \n",
       "   \n",
       "   \n",
       "   \n",
       "   \n",
       "   \n",
       "\fvii. Increase  with  positive  twist  to  the  following  net  change  after  ten  years   \n",
       "(interpolate for other durations):    \n",
       "  \n",
       "i. Year 1 spot rate  +0.5%    \n",
       "ii. Year 10 spot rate   +1.0%    \n",
       "iii. Year 30 spot rate   +1.5%   \n",
       "  \n",
       "viii. Increase with negative twist to the following net change after for ten years   \n",
       "  \n",
       "(interpolate for other durations):     \n",
       "  \n",
       " i. Year 1 spot rate  +1.5%    \n",
       "ii. Year 10 spot rate   +1.0%    \n",
       "iii. Year 30 spot rate   +0.5%   \n",
       "  \n",
       "257A. For purposes of calculating best estimate liabilities under the scenario-based method, the   \n",
       "future yield curves under each scenario would be determined as follows:   \n",
       "  \n",
       "a. Convert initial spot rates to the corresponding forward rates.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5938771",
   "metadata": {},
   "source": [
    "# 5. References\n",
    "- https://www.actuarialstandardsboard.org/standards-of-practice/\n",
    "- https://python.langchain.com/docs/use_cases/question_answering/quickstart\n",
    "- https://python.langchain.com/docs/use_cases/question_answering/sources\n",
    "- https://python.langchain.com/docs/integrations/text_embedding/\n",
    "- https://python.langchain.com/docs/integrations/vectorstores/chroma\n",
    "- https://docs.gpt4all.io/gpt4all_python_embedding.html#gpt4all.gpt4all.Embed4All\n",
    "- https://chat.langchain.com/\n",
    "- https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.chroma.Chroma.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628913a4",
   "metadata": {},
   "source": [
    "# Management of the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce4af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=db_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e514b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.delete_collection(name=\"CFT\") # Delete a collection and all associated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdeddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_collection(name=\"CFT\") \n",
    "collection.count()\n",
    "collection.peek()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ValAct_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
