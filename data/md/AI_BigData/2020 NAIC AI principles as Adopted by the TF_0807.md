# National Association of Insurance Commissioners (NAIC) Principles on Artificial Intelligence (AI) 

RECOMMENDS that insurance companies and all persons or entities facilitating the business of insurance that play an active role in the AI system life cycle, including third parties such as rating, data providers and advisory organizations (hereafter referred to as "Al actors") promote, consider, monitor and uphold the following principles according to their respective roles; and

THIS DOCUMENT is intended to establish consistent high-level guiding principles for Al actors. These principles are guidance and do not carry the weight of law or impose any legal liability. This guidance can serve to inform and establish general expectations for AI actors and systems emphasizing the importance of accountability, compliance, transparency, and safe, secure, fair and robust outputs.

## Further, THIS DOCUMENT

Should be used to assist regulators and NAIC committees addressing insurance-specific Al applications. The level of regulatory oversight may vary based on the risk and impact to the consumer. These principles should be interpreted and applied in a manner that accommodates the nature and pace of change in the use of AI by the insurance industry and promotes innovation, while protecting the consumer.

## Fair and Ethical

a. Al actors should respect the rule of law throughout the Al life cycle. This includes, but is not limited to, insurance laws and regulations, such as those relating to trade practices, unfair discrimination, access to insurance, underwriting, privacy, consumer protection and eligibility practices, ratemaking standards, advertising decisions, claims practices, and solvency.

b. Consistent with the risk-based foundation of insurance, AI actors should proactively engage in responsible stewardship of trustworthy AI in pursuit of beneficial outcomes for consumers and to avoid proxy discrimination against protected classes. Al systems should not be designed to harm or deceive people and should be implemented in a manner that avoids harmful or unintended consequences and corrects and remediates for such consequences when they occur.

## Accountable

a. Al actors should be accountable for ensuring that Al systems operate in compliance with these principles consistent with the actors' roles, within the appropriate context and evolving technologies. Any Al system should be compliant with legal requirements governing its use of data and algorithms during its phase of the insurance life cycle. Data supporting the final outcome of an Al application should be retained and be able to be produced in accordance with applicable insurance laws and regulations in each jurisdiction. Al actors should be responsible for the creation, implementation and impacts of any AI system, even if the impacts are unintended. Al actors should implement mechanisms and safeguards consistent with the degree and nature of the risks posed by AI to ensure all applicable laws and regulations are followed, including ongoing (human or otherwise) monitoring and, when appropriate, human intervention.

## Compliant

a. Al actors must have the knowledge and resources in place to comply with all applicable insurance laws and regulations. Al actors must recognize that insurance is primarily regulated by the individual states and territories of the United States as well as by the federal government, and that Al systems must comply with the insurance laws and regulations within each individual jurisdiction. Compliance is required whether the violation is intentional or unintentional. Compliance with legal requirements is an ongoing process. Thus, any Al system that is deployed must be consistent with applicable laws and safeguards against outcomes that are either unfairly discriminatory or otherwise violate legal standards, including privacy and data security laws and regulations.

## Transparent

a. For the purpose of improving the public's confidence in AI, AI actors should commit to transparency and responsible disclosures regarding Al systems to relevant stakeholders. AI actors must have the ability to protect confidentiality of proprietary algorithms, provided adherence to individual state law and regulations in all states where AI is deployed can be demonstrated. These proactive disclosures include revealing the kind of data being used, the purpose of the data in the Al system and consequences for all stakeholders.

b. Consistent with applicable laws and regulations, stakeholders (which includes regulators and consumers) should have a way to inquire about, review and seek recourse for Al-driven insurance decisions. This information should be easy-tounderstand and describe the factors that lead to the prediction, recommendation or decision. This information may be presented differently and should be appropriate for applicable stakeholders.

## Secure, Safe and Robust

a. Al systems should be robust, secure and safe throughout the entire life cycle so that in conditions of normal or reasonably foreseeable use, or adverse conditions, they can function in compliance with applicable laws and regulations. To this end, Al actors should ensure a reasonable level of traceability in relation to datasets, processes and decisions made during the AI system life cycle. Al actors should enable analysis of the Al system's outcomes, responses and other insurance-related inquiries, as appropriate in keeping with applicable industry best practices and legal requirements.

b. Al actors should, based on their roles, the situational context and their ability to act, apply a systematic risk management approach to each phase of the Al system life cycle on a continuous basis to address risks related to Al systems, including privacy, digital security and unfair discrimination as defined by applicable laws and regulations.