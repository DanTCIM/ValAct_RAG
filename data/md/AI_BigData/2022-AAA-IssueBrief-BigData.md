# Issue Brief 

## Key Points

This issue brief outlines the big data issues confronting the actuarial profession and presents a pathway for working with regulators to resolve them. It lays the foundation for a robust discussion on how big data and artificial intelligence are impacting the consumer insurance experience and how insurers and regulators can collaborate to resolve harmful impacts without stifling innovation.
American Academy of ACTUARIES

1850 M Street NW, Suite 300 Washington, DC 20036 202-223-8196 | www.actuary.org Craig Hanna, Director of Public Policy

## Big Data and Algorithms in Actuarial Modeling and Consumer Impacts

OCTOBER 2022

## Background

Algorithms fueled by big data are the infrastructure of artificial intelligence (AI). AI is having a tremendous impact on the business model of insurance with respect to the design, marketing, regulation, and servicing of insurance products. Some impacts are minor and incremental in nature, while other impacts are transformational with major implications. While insurance serves many socially useful functions, it may not be able to address all socially desirable outcomes while remaining sustainable and accessible. This issue brief outlines the issues confronting the actuarial profession and presents a pathway for working with regulators to achieve goals beneficial to consumers and to foster a regulatory framework that supports the future vibrancy of insurance.

The following framework and key concepts lay the foundation for understanding the limits of insurance systems to balance these two objectives.

## FRAMEWORK

The framework for traditional insurance is based on the need to manage the volatility of risk at an individual and a group level. Premium and product structures have traditionally had to account for the following elements:

- Mean Cost of Risk-The amount of expected claims.
- Cost of Volatility of Expected Claims-An additional cost for the insurance provider to have excess funds on hand for fluctuations from expected claims in order to assure both supervisors and shareholders that the company will survive adverse developments through holding
additional capital. This is in addition to the expected claim amounts. Because these funds are typically "borrowed" in order to sell a policy, they represent the additional costs needed to pay back those who contributed the capital needed to back the product.
- Cost of Uncertainty About the Mean and the Volatility-When this cost is hard to quantify, or estimates are subject to significant uncertainty, it is often addressed through product designs via limits on coverage, the use of dividends or nonguaranteed elements, or the use of premiums that reset each year.
- Cost to Market, Sell, Build \& Service Product, Fund Payments (Including Investment Risk) and Monitor Emerging Risk Expenses, and Disclose Performance of Operations-These costs are added to the average expected claims when setting the premiums for coverage and may also be included in additional required capital.

Big data and artificial intelligence will vary in their impact on each of these elements and will differ based on the nature and type of insurance offering. If any of these costs are not reflected in premiums or product design, then the insurer will not be sustainable in the long run. In the U.S., insurance supervisors are typically charged with ensuring that insurance is both accessible and sustainable.

## Key Concepts

1. The Business Model of Insurance encompasses certain services to be provided. It is helpful to assess which element of the value chain is being targeted by the use of big data and AI. Below is a listing of some of their most common areas of application:

- Distribution-Does AI or big data help identify the people and/or methods most able to effectively represent and carry out the insurer's marketing efforts?
- Customer-Do big data and AI provide a more satisfying customer experience, either at the time of sale or throughout the servicing of the policy?
- Selling-Do big data and AI streamline the sales process or help distribution channel(s) identify and sell to customers who would benefit from the insurance product(s)?
- Maintenance \& Servicing (Claims, Underwriting, Reserving)-Do big data and AI allow the insurer to provide these needed services in a more efficient manner?
- Fraud Detection-Do big data and AI ensure better identification of insurance fraud?
- Risk Management by the Customer-Do big data and AI allow or incentivize behavior or actions by the insured to reduce the level and volatility of their risk exposure (such as through wellness programs)?
- Price Prediction-Because setting the price is a "prediction" exercise based on data, can the use of big data \& AI provide better estimates of the mean and volatility of the risk-and thus allow for lower or less volatile premiums?
- Regulatory Oversight-Do big data and AI allow the supervision of insurance to be more effective and efficient?

2. Understanding Risk vs. Uncertainty-The work of Frank Knight, a $20^{\text {th }}$-century economist, draws attention to the difference between uncertainty and risk. Risk applies to situations where one does not know the outcome of a given situation but can accurately measure the odds. Uncertainty, on the other hand, applies to situations where one cannot know all the information needed to set accurate odds in the first place. All insurance lies on a spectrum bounded by measurable risk and complete uncertainty. Depending where on the spectrum a specific kind of insurance risk lies, tools used to price and structure the insurance offering will shift and differ. Life insurance can offer longer-term premium guarantees as the insurance is more "risklike." Similarly, auto insurance rates are more predictably steady as the risk is typically a high-frequency/low-severity kind of event. In contrast, we can consider the example of some catastrophic coverages where due to the lack of experience and data we are faced with a situation more in line with uncertainty.
3. Efficiency vs. Transformation-Does a big data analytic solution focus more on efficiency (expense savings) where the same process can be done less expensively or faster as seen in efforts to do the same process more quickly or cheaper? Or does it transform the way a service is provided, whether it be a transformation of the sales, underwriting, pricing or administration policies and procedures (as occurred with Uber \& Lyft for taxi services)?

## 4. Better Prediction vs. Better Judgment

- Does big data replace people or become a tool to enhance their judgment, creativity, and behaviors?
- Whether machine learning mimics functions and analysis performed by an actuary, underwriter, or claims manager, or uses an AI algorithm to learn on its own what is the end result of that process? Does it replace individuals or augment and accelerate their capabilities?

5. Evaluating the Data Asset-Understanding, uniformly across the industry, the quality of existing data assets, requirements for sufficient data remediation and/ or enrichment, and ongoing investment in data quality is a critical consideration in applications of AI and ML now and into the future.
6. Regulation and Oversight-What is an appropriate role for regulation to both foster innovation and enable transactions while safeguarding consumer privacy?

The role of the actuary continues to evolve along with the tools used to perform actuarial work. There have been many developments in actuarial practice since the days where assumption-setting relied solely on data from company policy master files. Using big data, we can explore and investigate additional patterns of behavior that can drive the risk being insured and the manner of its delivery and servicing.

## Actuarial Standards of Practice ("ASOPs")

The ASOPs, promulgated by the Actuarial Standards Board (ASB), provide guidance for actuaries when performing actuarial services and identify what the actuary should disclose when communicating the results of those services. They do not prescribe every step in an actuarial assignment, nor do they dictate a single approach or outcome. Rather, the ASOPs require the actuary to follow a process while allowing the actuary to use professional judgment when selecting assumptions, relevant data, and advanced statistical techniques. It is possible for different actuaries using the same data and the same advanced statistical technique to reasonably reach different but justified conclusions. They may justifiably model the data differently even if they are using the same assumptions and objective function. The following ASOPs serve as useful guidance to actuaries working with big data and algorithms:

- ASOP No. 1, Introductory Actuarial Standard of Practice
- ASOP No. 2, Nonguaranteed Charges or Benefits for Life Insurance Policies and Annuity Contracts. This ASOP is applicable if big data and AI are used to determine nonguaranteed elements.
- ASOP No. 7, Analysis of Life, Health, or Property/Casualty Insurer Cash Flows. This ASOP is applicable in cases where actuarial assumptions are influenced by advanced analytics techniques.
- ASOP No. 12, Risk Classification (for All Practice Areas). This ASOP applies to the selection of risk classification models derived using machine learning techniques.
- ASOP No. 15, Dividends for Individual Participating Life Insurance, Annuities, and Disability Insurance. This ASOP is applicable when machine learning is used to set assumptions or dividend determinations.
- ASOP No. 23, Data Quality. This ASOP provides guidance when selecting data, performing a review of data, using data, or relying on data supplied by others in performing actuarial services.
- ASOP No. 38, Catastrophe Modeling. This ASOP applies when studying effects of large-scale, low-frequency, high-severity events such as hurricanes, earthquakes, tornados, terrorist acts, and pandemics.
- ASOP No. 41, Actuarial Communications. This ASOP discusses critical standards for communicating actuarial results.
- ASOP No. 54, Pricing of Life Insurance and Annuity Products. This ASOP applies to actuaries performing actuarial services with respect to pricing-that is, setting rates, charges, and benefits.
- ASOP No. 56, Modeling. This ASOP provides guidance when performing actuarial services with respect to designing, developing, selecting, modifying, using, reviewing, or evaluating models.

The use of big data and algorithms are still in their relative infancy in actuarial practice, though it is more mature in some practice areas than in others. At the same time, the field of artificial intelligence is continuing to advance and new applications for insurance will emerge. It is likely the current set of ASOPs may not be robust enough to contemplate future uses of big data and $\mathrm{AI}$ and will require future updates and additions.

It is important to recognize that while ASOPs are guidance for actuaries, they are not guidance for non-actuarial data scientists building risk classification systems and pricing models that require regulatory review. Some regulators may not be familiar with the rigor the ASOPs impose on the work of actuaries and may not consider the ASOPs in their review and assessment of actuarial work products. While these observations present challenges for actuaries, they also present an opportunity for actuaries working as regulators or with regulators to reinforce the high standards actuarial work products are held to by the ASOPs.

To build trust among regulators, it will be helpful to develop AI model review standards that address the concerns of regulators reflected in the National Association of Insurance Commissioners (NAIC) guiding artificial intelligence principles. Under this guidance, persons building AI models in the conduct of insurance should address the principles below in the use of big data and AI. The NAIC believes that the use of big data and AI should be: ${ }^{1}$

- Fair and Ethical: Respecting the rule of law and implementing trustworthy solutions.

1 “NAIC Unanimously Adopts Artificial Intelligence Guiding Principles”; NAIC; Aug. 20, 2020.

- Accountable: Responsibility for the creation, implementation, and impacts of any AI system.
- Compliant: Have knowledge and resources in place to comply with all applicable insurance laws and regulations.
- Transparent: Commitment to responsible disclosures regarding AI systems to relevant stakeholders as well as ability to inquire about and review AI-driven insurance decisions.
- Secure/Safe/Robust: Ensure reasonable level of traceability of datasets, processes, and decisions made and implementation of a systematic risk management process to detect and correct risks associated with privacy, digital security, and unfair discrimination.

It may be important to demonstrate to regulators where the ASOPs intersect with these principles and to resolve areas of difference to promote a healthy partnering in the interest of strengthening public trust.

## Ethics and Artificial Intelligence

Promoting the ethical use of data and AI modeling begins with a few core principles which are reflected in the NAIC AI guiding principles. These principles can be operationalized through several key practices when utilizing big data and AI modeling to build actuarial work products. Some of these practices are addressed in the ASOPs. The practices can be summarized as follows:

- Transparency and Privacy: Transparency means insurers disclose data sources and feature engineering to transform data into model input data. Feature-engineered data can be unrecognizable to consumers, impeding their ability to correct it for errors. Consumers must have the ability to inspect data used to determine their risk classification and premium rate for accuracy and must be afforded the right to correct erroneous data. Insurers take steps to ensure consumer data will be secure from misuse by internal and external bad actors.
- Data Quality: It is important that data sources are: 1) applicable to the modeling question and current, 2) reconciled to auditable sources and expert judgment, 3) tested for credibility, representativeness, balance, and accuracy, and 4) audited for biases and proxies for regulatory disallowed variables. This means model training data must be trustworthy, representative, and reflect a strong relationship to the risks being insured.
- Model Purpose and Limitations: A model should clearly identify its purpose, appropriate usage, and limitations. This includes the relevancy of model inputs, applicable cohorts to which they apply, the conditions under which they apply, and metrics signaling when they are no longer applicable. Models need appropriate human oversight to monitor when calibrations are needed to detect when models may no longer fit the data or the problem.
- Responsible Research: It is important that research supporting the development of $\mathrm{AI}$ is based on credible scientific principles and practices and clearly reference the modeling question. It should be well documented with tractable findings that have been tested for unintended consequences and statistical biases.
- Correlation, Causation, and Consistency: Care should be taken to understand and communicate the model decisioning path and distinguish whether the patterns detected by models can be qualified as causal vs. associative in nature. Correlations must be assessed for strength and quality of their associations. Correlations should be evaluated to ensure they are not spurious through research, experience, and observable behaviors. The gold standard for assessing causation is the randomized control trial (RCT) often used in evidence-based medicine to prove a certain treatment is a cure for a disease. ${ }^{2}$ Most actuarial models fall short of this standard, as RCTs are experiments run over long periods with many study subjects. Predictive models look for patterns of association or correlation in modeling data but cannot be relied upon to assess causation. Also, certain advanced modeling algorithms can become unstable in the presence of correlated variables and great care should be taken and attention paid to their removal.
- Proxies for Disallowed Variables: Facially neutral variables become problematic when they unintentionally mimic regulatory disallowed variables and disproportionately harm protected classes. It is also important to recognize that a disallowed variable in one state may be allowed in another. Regulatory differences are a prime reason that a company's model in one state might differ in form in another state. Variables in a model that derive their predictive power from their correlation with a legally prohibited characteristic are not necessarily utilized with ill intent. Proxy variables that do not pose risk of harm may be useful modeling variables for attributes that are not readily accessible through internal company or third-party data sources.
- Interpretability and Explainability: In AI nomenclature, interpretability refers to the ease with which a model can be understood without external assistance, while explainability is just the opposite, requiring external aids in its explanation because of its complexity. Both interpretability and explainability are essential in challenging outcomes of algorithms and the independent replication of their results. Model validation addresses these issues when it includes effective challenge procedures and documented audits of fit to purpose, dependencies, data quality, decisioning, and controls and governance of outputs and conclusions.
- Diversity in Model Development and Review: To protect against programming biases into the model, as well as model drift over time, it is good practice to have a diverse set of reviewers (e.g., by gender, ethnicity, race, age, and training) of various AI inputs, decisioning and outputs relevant to the intended purpose. This provides greater perspective regarding potential biases and unintended consequences.

Two main sources of algorithmic bias are biased training data and biased programmers. Fixing biased training data may be easier to resolve than diversifying the model building team, but this is not simply a pipeline problem. Diversity is also effectuated by diverse cross-functional experience that includes practitioners across the business. The crossfunctional team should include underwriters, business analysts, actuaries, statisticians, programmers, and even legal counsel to aid in review of model variables for unfair discrimination.

## Traditional Actuarial Risk Classification \& Pricing

In Actuarial Standard of Practice No. 12 (ASOP No. 12) on risk classification, the Actuarial Standards Board (ASB) describes actuarial risk classification as a tool for establishing risk pricing The American Academy of Actuaries further expanded on the purpose and design and management of risk classification systems in its public policy monograph on risk selection, published in $2011 .{ }^{3}$ The process of risk classification involves grouping risks with similar risk characteristics. One goal is to achieve equitable insurance pricing. Risks are grouped together to determine averages, which are then applied to individual risks. The ASB is clear that the purpose of risk classification is not to reward or penalize certain groups of risks, especially at the expense of other groups. The Risk Classification Statement of Principles (SOP), as discussed in the monograph, requires risk classification to serve three purposes: protect the insurance system's solvency, be fair, and permit economic incentives to operate that will encourage widespread availability of coverage.

3 On Risk Classification; American Academy of Actuaries; November 2011.

The SOP further lays out five principles for a sound risk classification system:

- The system should reflect expected cost differences.
- The system should distinguish among risks on the basis of relevant cost-related factors.
- The system should be applied objectively.
- The system should be practical and cost-effective.
- The system should be acceptable to the public.

These principles are in keeping with regulatory concerns that insurance rates are adequate, not excessive, and not unfairly discriminatory. Charging tobacco users higher life insurance premiums than non-tobacco users is consistent with higher expected costs for the risks to health that smoking poses.

Risk classification is inherently a competitive tool by design. Insurance companies that optimally distinguish better risks from worse risks through risk appropriate pricing will outperform their competitors. In the tobacco example above, insurance companies with aggregate rates for tobacco and non-tobacco users would end up with more tobacco users in its risk pool, resulting in higher aggregate insurance rates. Non-tobacco users would opt for a cheaper coverage from an insurer with lower non-tobacco rates, thus further increasing the proportion of tobacco users in the pool of the insurer with aggregate rates. This further deterioration of the aggregate insurance pool could turn into an adverse selection risk spiral. Life insurance companies collect biometric data for risk classification. Some examples of this data include blood pressure measures, family history, body mass index (BMI), cholesterol data, and blood and fluid tests. Co-morbidities-the simultaneous presence of multiple health issues-are examined as well, as the presence of multiple risk factors significantly increases mortality risk. An unfavorable rating could result in a policy being rated substandard and require a higher premium rate. In some cases, this data could lead to a policy being declined for insurance. Favorable measures of biometric data may result in classifying a risk as a preferred risk and result in lower premium rates. Behavioral and occupation risk classifications based on activities or occupation of the insured are also indicative of potential loss. Examples of activities or occupations indicative of high-risk classifications include prior driving under the influence (DUI) record, holding a pilot's license, or being employed in dangerous occupations (e.g., mining or active military). Disclosure of these activities on the insurance application may result in permanent or temporary higher rates (e.g., flat extras), or even declination of insurance coverage.

Across all practice areas, risk classification is a holistic process, where each variable is less important than the overall picture of how individual pieces fit together. For example, diabetes is a risk factor, but this risk is significantly reduced if diabetes is managed. Having diabetes is a negative risk factor but an "active diabetic" who mitigates their condition with proper weight management may be worthy of a lower rate than a "sedentary diabetic." As another example, in a flood zone a home may be less of a risk if elevated versus one that is not.

Big data techniques are used in risk selection to identify rating variables predictive of risk. Each risk rating variable should be examined through the lens of ASB guidance set above, as well as ASOP No. 12, Risk Classification discussed above. Nonconformity of a model to these standards should be a red flag that the model may violate regulatory requirements that rates should be adequate, not excessive and not unfairly discriminatory.

## Behavioral Inference Impact of Big Data on Traditional Practice

Sherry Turkle of the Massachusetts Institute of Technology (MIT) says, "Technology does not just change what we do, it changes who we are." 4 This statement reminds us that we must be mindful and watchful of the behavioral effects of technology in shaping the data we study, and the models built upon that data. A prime example of this is the use of self-quantification devices like Fitbit wearables, which have driven users to psychological imperatives to achieve 10,000 steps before bedtime, taking those last few needed laps around the dining room table to do so. The benchmark of 10,000 steps has no real scientific validation but has become a fitness norm nonetheless. Self-quantification data can reveal several highly desirable traits in policyholders, such as self-efficacy and selfregulation. Self-efficacy, for example, refers to one's belief in his or her capacity to execute behaviors necessary to achieve a goal. ${ }^{5}$ People of high self-efficacy are drawn to selfimposed challenges, such as achieving 10,000 steps per day, and need very little external "nudging"' to complete tasks.

Data brokers provide in the marketplace "behavioral" data that are finding their way into insurance predictive models where insurers have limited ability to inspect its reliability, accuracy, and veracity. There are companies (e.g., LexisNexis, Experian, and Acxiom) that are monetizing behavioral and lifestyle attributes at a person-level, collected through surveys and public sources. Insurance companies are including these data as features in predictive models. There are several areas of concern emerging with use of these data. These areas of concern include:

4 "Afterword: Reclaiming psychoanalysis: Sherry Turkle in conversation with the Editors"; Psychoanalytic Perspectives; 2017. 5 "Analysis of self-efficacy theory of behavioral change"; Cognitive Therapy and Research; 1977.

6 Nudge: Improving Decisions About Health, Wealth, and Happiness; Richard Thaler and Cass Sunstein; 2009.

- Embedded bias toward protected classes. Insurance companies currently are forbidden by state statutes from collecting data on race. Data brokers are not limited by such regulatory mandates. They can collect race and use it to create new variables which inherently discriminate against protected classes. Currently, there are no regulatory agencies certifying the quality of third-party behavioral and lifestyle data.
- Limited access to credible amounts of behavioral, lifestyle, and physiological data to validate a real pattern of behavior, and an understanding of how much data are needed to identify real behavioral traits.
- Lack of transparency in the collection, data engineering, and analytical methods of data brokers to determine whether data elements are biased toward protected classes.
- Facial recognition software biased against protected classes that insurers may use to detect fraud in online insurance applications and insurance claim filings.
- Biased training data and biased programmers are emerging as prominent issues in predictive modeling and AI technologies and proving to have disparate impacts. ${ }^{7}$ Concerns are emerging that algorithms trained on historical data may embed gender and racial bias.
- Lack of rigorous regulatory policies that apply to digital practices to identify how algorithms might trigger discrimination; and lack of regulatory sandboxes to foster anti-bias experimentation and safe harbors to curb online biases.
- The ethics of insurers studying and surveilling human behavior through their personal data for risk-profiling purposes. ${ }^{8}$ Understanding customer preferences must be distinguished from making character trait attributions based on what may be flawed data from data brokers.

These issues require more study. In addition, the application of ASOP Nos. 23 and 56 is needed to ensure that data and models are developed with the least amount of bias and used appropriately. The regulatory perspective is important to develop guidelines that ensure consumer protections are preserved, while still allowing for an improved customer experience through the use of additional data sources and advanced modeling techniques.

## The Reliability and Regulation of External Data Sources

The development and advancement of technology and computing power have enabled insurance companies to capture and utilize broader types of datasets to include external data sources. This data is often pre-packaged and can be fed into insurance company systems in real time. Some data may come in a structured format while other data may be semi-structured or fully unstructured in form. Some data may be unprocessed, and some data may have been cleansed by external third-party software. Data from external sources may contain biases, errors, and missing values that can be remedied or identified.

The quality and purpose for which data were collected need to be reviewed for alignment with any new application for which it may be used. Data processed by a third-party algorithm may be ill-defined for the intended use of an insurance company and compromise its value proposition. Companies using nontraditional external sources of big data may have less upfront control than when using traditional sources of data. The broad source of data may have been regulated under different regulatory regimes and jurisdictions or some may not have been subjected to regulation. The traditional data validation process may not fit in this emerging new big data model, and there is a lack of independent data source validation. Currently there are no regulatory agencies that regulate, validate, and certify nontraditional data sources in the insurance industry.

Actuaries can find guidance in ASOP No. 23 when reviewing data for inclusion in models. The principles of ASOP No. 23 could be valuable guidance for insurance companies-even when non-actuaries are involved-in assessing the quality and applicability of data before it is used. The principle is to validate whether the data are appropriate, relevant, compatible, and current for the risk classification and pricing exercise. The questions that should be asked are: 1) whether the data source can be relied upon for the given purpose, and 2) whether the data will help achieve the objective of the model. Companies may need to upgrade their governance framework to include:

1. Validation of external data sources for quality,
2. A review of third-party data collection procedures,
3. Quality assurance guidelines for external data sources, and
4. Analysis of data for compliance with any existing regulatory requirements.

It may be challenging for a company to access and explain internal data processing and algorithms used by third-party data providers. The company may be able to overcome this challenge by demonstrating that the external data poses no harm to consumers and does not contain variables that serve as proxies for disallowed variables. This can help build trust with regulators and consumers.

## Controlling for Systemic Influences and Socioeconomics

Bias can enter the modeling process in a myriad of ways. The early entry point of bias in the modeling process is in construction of the dataset. It has been acknowledged in the literature that all datasets reflect bias, and most modelers are either unaware of inherent biases in datasets or are not trained to resolve them. ${ }^{9}$ If modelers do not interrogate modeling data to understand how they were generated and any preprocessing, they may have imbued the modeling results with bias. Algorithms may fail to detect predictive patterns in data when confounding variables, which are often social science variables, are not considered when interpreting results. For example, a health algorithm based on a health care cost metric may deem certain segments of the population as heathier than others without considering the systemic issues that influence medical spending and lack of access to health care in those very same segments. In this case, the signal was confounded by systemic issues-the social science variables. Interrogating model data might start with addressing questions such as:

1. Who is left out of the data, and what are the implications for model results of the exclusion?
2. How representative is the data for the population to which the model will be applied?
3. What historical biases are embedded in the data?
4. What are the societal biases that can explain historical biases?
5. What preprocessing was done to the data before it was engaged for the modeling exercise?
6. Have the data been inspected for biases such as response bias, selection bias, system drift bias, omitted variable bias, and societal bias?10

It is important to focus on interrogating the data. The data make the algorithm, not the other way around.

The second entry point of bias is the modeling process. The modeling process can invite bias if programmers infuse faulty assumptions with their interpretations of phenomena being modeled. The lack of diversity of the modeling team poses the potential threat of a blind spot in interpreting modeling results and bridging the gap between model predictions and causal inferences. Modeling should be an interdisciplinary exercise that involves expertise beyond that required to understand complex mathematical algorithms to avoid signal problems and blindness to social science variables that may be important in understanding model results using qualitative research. It is incumbent upon modelers to enlist diverse perspectives in analyzing model results to prevent biases from entering every phase of the modeling process.

9 "What Do We Do About the Biases in AI?"; Harvard Business Review; Oct. 25, 2019. 10 This reference is a good primer on these biases.

A third entry point of bias is in the application of the model. A well-known saying in predictive modeling is, "All models are wrong, but some are useful." Model risk is compounded when models are applied to the wrong problem and when modeling data violate theoretical assumptions of a modeling technique. Even when a model perfectly fits the data, the model may be poorly approximated, poorly implemented, and poorly interpreted, producing biased results that are then acted upon as if they represent "truth." Models require rigorous model validation by an independent body of diverse experts not involved in building the models, and whose sole function is to ensure models put into production are mathematically sound and do not pose model risk to companies and consumers.

This discussion provides a basic framework for assessing how bias can enter a model. It is important to develop assessment tools and metrics that identify biases throughout the process so they may be resolved.

## Regulatory Concerns Impacting the Work of the Actuary

There is growing concern among regulators over the use of big data, reliance on external data sources, and engagement of non-actuarial resources in designing and building assumptions, underwriting, and pricing models. ${ }^{11}$ Nontraditional data are becoming vital sources of underwriting data as technology is enabling consumers to self-quantify and connect through virtual media platforms. These new sources raise data ownership and privacy concerns. The second major issue is the challenge to validate external data and confirm that they comply with regulatory standards rather than rely on vendor assertions of data quality. A third issue arises when the model is built by external resources and there is not sufficient internal company expertise to validate the model and its inputs and outputs. Regulators want to be assured of the quality of the data, its use, and that model algorithms do not unfairly discriminate against consumers. Models should be adequately documented, allowing for replication, and modelers should adequately describe model assumptions and algorithms not only for internal key stakeholders, but also in order to have appropriate transparency for the public.

It is important for insurers and regulators to work together to establish mutually satisfactory processes that address the following key issues:

1. How to ensure that insured data is securely maintained and only used for the intended purpose.
2. How to determine that key variables in actuarial models are not unfairly discriminatory or proxies for regulatory disallowed variables.

11 Insurance Markets: Benefits and Challenges Presented by Innovative Uses of Technology; Government Accountability Office; June 7, 2019.

3. How to identify statistical biases in modeling data and ensure key variables have an appropriate relationship to the risk being insured.
4. How to ensure explainability and interpretability of modeling algorithms and results as companies adopt machine learning algorithms more advanced than Generalized Linear Modeling.
5. How to ensure the appropriate level of granularity of underwriting results to guard against unintended disparate impacts to protected classes. Insurance companies need to validate the appropriateness of key variables used in models and verify the quality of the data with actuaries or experts who understand insurance company target markets, product lines, and liabilities which is the context to which the data and models are applied.
6. How to ensure companies are not allowing "black box" algorithms to run unattended by human oversight. Human oversight ensures that controls and metrics are in place to monitor continued fit and appropriateness of models for the purpose for which they were designed.

New York State Insurance Circular Letter No. 1 issued in $2019^{12}$ can be a useful reference and is an important regulatory consideration for insurance companies. This circular letter covers the use of external data and certain approaches in data analytics and predictive models. Though this circular letter is applied to life insurance companies and their use of external data and information sources in underwriting, the guidelines can inform other insurance practice areas as well. The guidance recognizes the use of external data from nontraditional data sources and the potential benefits of simplified underwriting and life insurance sales processes to improve the underwriting and deployment of insurance policies. The circular letter also highlights that external data and algorithms can have a negative impact on the availability and affordability of life insurance for protected classes of consumers. This is a concern that requires the cooperative efforts of regulators and insurers to effectively address.

12 “Insurance Circular Letter No. 1 (2019)”; New York Department of Financial Services; Jan. 18, 2019.

## Impacts of Big Data to Transform the Practice of Insurance

There can be no doubt that every aspect of insurance is in the midst of a transformation driven by the technological innovations of InsurTechs, the predictive power of advanced analytics, and AI technologies. Actuaries are reckoning with the realization that the traditional actuarial toolkit should be updated to include the necessary tools to analyze new data being generated by new technologies vital to improving the classification and pricing of risks, current and emerging. The actuarial profession is evolving to prepare actuaries to embrace new technologies and mine generated data for actuarial insights, as evidenced by an increasing focus on machine learning in actuarial education curricula for credentialing. However, actuaries cannot evolve the practice of insurance without partnering with regulators to ensure innovations do not compromise consumer protections.

It is no surprise that transformation is accompanied by disruption as the profession has already witnessed with the arrival of InsurTech catching the industry off guard. The use of machine learning techniques and big data in actuarial modeling has raised some regulatory concerns about consumer protections. Three major learnings resulted from this experience, which are important for the industry to remain cognizant of, are:

1. A call for algorithms to "First do no harm," lest harm be done to reputations and consumers. Algorithms and their training data must meet high standards and modeling teams must be diverse to mitigate biases toward protected classes.
2. Address issues of accessibility and sustainability. Insurance was not designed to solve all social systemic problems, but certainly should not contribute to them by limiting the availability and affordability of insurance products. AI \& big data, reinforced by regulatory policies, may be deployed to identify those who might benefit from microinsurance or some other public policy solution to reduce the cost of risk protection.
3. Take a multidisciplinary approach in developing and adopting AI. There is ample evidence that diverse and multidisciplinary approaches result in more effective and less biased solutions. As is the case with many technical and highly specialized fields, the actuarial profession is not as diverse relative to the general population. Research suggests the lack of diversity is problematic for algorithmic bias mitigation. When there is a lack of diversity and interdisciplinary expertise on modeling teams, other measures to mitigate bias become even more important to build trust between insurers, the public, and regulators. These measures include:
a. Target variable analysis

b. Independent audit of results

c. A focus on the composition of training data

d. Greater transparency of algorithm methodology

e. Validation metrics to relieve concerns of algorithmic bias

Of course, even in the best of circumstances, bias will still creep into algorithms, but it is only with observable vigilance to identify and remove bias that the profession can maintain the trust, confidence, and respect of regulators and the public. This also presupposes that the regulatory environment will adopt secure regulatory technology to ensure insurers can be transparent with regulators, without compromise of company trade secrets. It will be essential for both the regulatory environment and the industry to evolve in the interest of the public good.

