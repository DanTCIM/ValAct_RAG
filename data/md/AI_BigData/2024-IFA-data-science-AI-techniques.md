# Actuaries using data science and artificial intelligence techniques
## Thematic Review Report 

by AIan Marshall

<img src="https://cdn.mathpix.com/cropped/2024_04_02_556b9fff27797a776798g-01.jpg?height=191&width=2062&top_left_y=2440&top_left_x=0" alt="image" style="width:50%;height:auto;">

<img src="https://cdn.mathpix.com/cropped/2024_04_02_556b9fff27797a776798g-01.jpg?height=184&width=2060&top_left_y=2609&top_left_x=-2" alt="image" style="width:50%;height:auto;">

<img src="https://cdn.mathpix.com/cropped/2024_04_02_556b9fff27797a776798g-01.jpg?height=146&width=2062&top_left_y=2777&top_left_x=0" alt="image" style="width:50%;height:auto;">

## Contents

	Foreword ..... 3
	Introduction ..... 4
	Executive summary ..... 5
	Report structure ..... 6
	Background and context ..... 7
	Involvement of Actuaries ..... 9
	Standards and regulations ..... 15
	Learning and collaboration ..... 19
	Findings and conclusions ..... 21
	Appendix 1 - Scope and approach ..... 23
	Appendix 2 - References ..... 24
	Appendix 3 - Abbreviations ..... 26
	Appendix 4 - Examples of conference topics ..... 27

## Foreword

## Neil Buckley, Lay Chair of the IFoA Regulatory Board

<img src="https://cdn.mathpix.com/cropped/2024_04_02_556b9fff27797a776798g-03.jpg?height=582&width=469&top_left_y=674&top_left_x=148" alt="image" style="width:20%;height:auto;">

I welcome the publication of the Actuarial Monitoring Scheme's (AMS) latest report, Actuaries using Data Science and Artificial Intelligence techniques. This continues the regulatory work of the Institute and Faculty of Actuaries (IFoA) in independently reviewing areas of work in which actuaries have significant involvement and influence. I would like to thank all those IFoA members and organisations that took part.

This report provides a timely update on both the activity of actuaries in this fast-paced environment, and the latest regulatory developments around the world. At our February 2024 meeting, the IFoA Regulatory Board had a wide-ranging discussion on the findings of the report. A key area of interest for the Regulatory Board is fairness and ensuring that in the use of data science in modelling, whether or not it uses AI, there is a sufficient transparency and public interest focus. It is important that outcomes balance commercial interest and consumer fairness, and that actuaries play their part in helping to ensure this happens.

The Board recognises that, given the significant ongoing regulatory activity in many countries, there is a balance to be struck with any further IFoA specific actions, especially as the environment in which actuaries are working in data science and AI will undoubtedly continue to evolve. There was discussion around what actuaries should consider, depending on whether they are involved in building complex models, or where they are reviewing or using output from such models. Over time it may be appropriate to consider to what extent different aspects of the IFoA regulatory toolkit can best support actuaries in different roles. At this stage, the Board supports a review of our current ethical and professional guidance for data science, and the continued development of professional skills material in this area. Additionally, we will continue to engage with IFoA members and volunteers taking an active interest in $\mathrm{AI}$ and data science and encourage collaboration with global actuarial associations and other agencies to help drive responsible and ethical use of emerging technologies in the public interest.

This is an area of actuarial work that will continue to be a focus for the Regulatory Board, and we look forward to ongoing engagement with members.

## Neil Buckley

Lay Chair of the IFoA Regulatory Board

February 2024

# Introduction 

AIan Marshall, Review Actuary

<img src="https://cdn.mathpix.com/cropped/2024_04_02_556b9fff27797a776798g-04.jpg?height=603&width=469&top_left_y=681&top_left_x=151" alt="image" style="width:20%;height:auto;">

Whilst actuaries should be humble about claims of being "the original data scientists", the profession has been, and continues to be, well-placed to use data science, and associated modelling techniques to provide solutions to a wide range of problems. And although much of this is not brand-new, there is certainly a heightened focus on data science and artificial intelligence ('AI'), with both access to models and tools, and capability of the technology expanding rapidly.

This brings into play increased risks and opportunities for our members, and a responsibility to play our part in ensuring safe, transparent, and inclusive use of the technology in the public interest. This is not to discourage innovation, rather to support and promote the work of actuaries across existing and new domains, in a way that serves the wider good of society and seeks fair outcomes from data science and AI.

The aim of our thematic review is to highlight examples of where actuaries are using or developing new ways to use existing and emerging data science techniques. We have gathered various case studies where actuaries are applying or looking to apply their skills in this area. Additionally, we have outlined some of the developing standards and changing regulatory landscape across the globe, with a view to help inform actuaries of the environment in which they are working.

Thank you to everyone who has participated and given time to our review, this has undoubtedly helped us in assessing relevant findings to support both our members and the regulatory activity of the Institute and Faculty of Actuaries ('IFOA'). I hope the findings and conclusions are of interest to a wide audience and we look forward to ongoing discussions and debate in this exciting field.

## AIan Marshall

Review Actuary

February 2024

## Executive summary

## These headline findings and conclusions aim to highlight the involvement of actuaries in data science work, along with key areas of potential risk.

## Rapidly changing environment

Increased capacity, availability, and profile of data science and AI tools all feeds into a rapidly changing environment. This, coupled with technological advances and ever-growing sources of data, potentially changes existing risks, and introduces new risks where such tools are adopted in areas of actuarial work.

From a regulatory perspective, both in the UK and globally there is evidence of governments and agencies developing knowledge and resources, with an increasing focus on safe adoption and use of AI. There is likely to be emerging standards, rules, and regulations in several jurisdictions, with challenges around consistency of aims and outcomes.

## Increasing level of involvement of actuaries

There is an increasing level of actuarial involvement in $\mathrm{AI}$ and data science across a range of domains, and also plans to further increase usage. The range of application of these techniques is widening significantly into many traditional actuarial areas of work. There is also some evidence of emerging involvement of actuaries in wider fields.

Often actuaries will be working alongside data scientists, and other experts, with organisations being more focused on relevant skills than professional qualifications. This may bring challenges in maintaining demand for actuaries in certain types of work, at a time where there is increasing demand from employers to use data science and AI techniques.

## Supporting actuaries

The IFoA supports its members through standards and guidance, lifelong learning, and support for volunteers.

The principles of the Actuaries' Code are relevant, and there is also additional non-mandatory guidance covering ethical use of data science in the public interest.

At present there is material in parts of the underlying Associateship and Fellowship curriculum for actuarial students. Additionally, there have been lifelong learning opportunities, for example through the IFoA Data Science certificate. There are ongoing plans to develop both of these strands to help ensure our members continue to be well-placed to contribute to this field.

## Opportunities to collaborate

The IFOA has a strong record of collaboration with other stakeholders in prominent fields of work. There exist wide-ranging opportunities to continue this in data science and AI, seeking out new avenues to influence future paths. There is extensive ongoing IFoA volunteer activity, further supported by IFoA executive teams, which can help drive this.

## Main conclusions

- The increasing use of data science and AI, and the demand for relevant skills, presents continuing opportunities for actuaries. To remain competitive actuaries will need evolving resources covering professional development and standards to support them as builders or users of AI systems and outputs.
- There is considerable change and activity from a global regulatory perspective, with further developments expected to focus on responsible and ethical use of emerging technologies. This provides important context for the IFOA and other regulators in considering actions which continue to provide clear expectations and support to actuaries working in this domain. There will be challenges in ensuring standards and guidance remain proportionate and relevant to the growing applications of data science and AI where actuaries may apply their skills, whilst recognising the changing risk landscape.


## Report structure

## How this report should be read

We have set out in this report the detailed results of our thematic review. The Executive Summary sets out our key findings and conclusions; a full list can be found on page 20.

## Findings and conclusions

The main output of this review is a series of findings based on the questionnaires and case studies submitted, conversations with actuaries in this field, and analysis of other relevant sources and material.

We have also set out conclusions highlighting where actuaries, regulators and other stakeholders might consider further work to follow-up in light of one or more of the findings.

## Case studies

We have highlighted several case studies in the Involvement of actuaries section of this report. These are based on the submissions made by organisations and individuals to this thematic review. In some cases, we have edited or supplemented the case studies to aid clarity or to reflect comments made in follow-up discussions.

## References and abbreviations

Referenced documents or webpages are shown by footnotes on the relevant page. A full list of documents is set out in

Appendix 2. AIthough abbreviations are defined when they first appear in this report, a full list is set out in Appendix 3.

## Status of report

This report has been prepared by the IFoA Review Team and is issued by the Regulatory Board of the IFoA. Its purpose is to report on findings of the thematic review on the involvement of actuaries in data science work.
This report imposes no obligation upon members over and above those embodied in the Actuaries' Code ${ }^{1}$ (Code) or the IFoA Standards Framework, ${ }^{2}$ which includes compliance with the Technical Actuarial Standards (TASs) set by the Financial Reporting Council (FRC). It is intended to be helpful to the IFOA and other regulators when considering developments in standards and regulation. It is also intended to help actuaries in their work in this field.

This report does not constitute legal advice. While care has been taken to ensure that it is accurate, up to date and useful, the IFoA does not accept any legal liability in relation to its content.

## Review of this report

An earlier draft of the report has been subject to review by an IFoA colleague with data science knowledge, who did not otherwise take part in the review.

This, along with additional editing reviews, is considered by the author to meet the Work Review requirements of Actuarial

## Profession Standard (APS) X2.

We wish to thank the above individuals for their review comments, although the contents of this report, in particular the findings and observations within, remain the responsibility of the IFoA Review Team.

## Conflicts of interest

We are not aware of any conflicts of interest arising from the contents of this report in relation to the Review Team that carried out the work or the Regulatory Board that has commissioned the review work.

## Questions about this report

We welcome questions about this report which should be sent to reviews@actuaries.org.uk

<img src="https://cdn.mathpix.com/cropped/2024_04_02_556b9fff27797a776798g-06.jpg?height=134&width=990&top_left_y=2554&top_left_x=190" alt="image" style="width:100%;height:auto;">

# Background and context 

"When I heard actuaries described as the original data scientists, I really liked the<br>phrase. It captures the essence of what actuaries have been doing for centuries.<br>If you look back at the pioneers of the profession, they were analysing what at the<br>time were large data sets to do with longevity, trying to find the truth and insight in<br>them, and then extrapolate into the future. Then if you look back to just a decade or<br>two, actuaries did similar things around Stochastic asset models - and, again, trying<br>to make projections into the future. And that's the essence of what data scientists try<br>to do. The tools and technology used have moved on massively, of course, but the<br>fundamentals of trying to extract truth and insight from data, and then using that to<br>infer something about the future, are the same."

So said John Taylor, Past President of the IFoA back in 2019, as he eloquently made the case for actuaries as data scientists.

Around 2018, the IFoA had started to ramp up its focus on data science and develop resources to support members active or interested in this domain. At that time the profession was lucky to have a number of members who had been active in data science for some time, and with their help, and the help of others outside the IFOA, data science started to be more actively promoted for members.

This led to lifelong learning material and opportunities being promoted to members, and in 2019 to the introduction of the IFoA Certificate in Data Science, in conjunction with University of Southampton. There was also an increase in IFoA volunteer activity in this topic, and the Data Science Community was formed with various workstreams, and a dedicated online community hub for interested members.

AIl this activity reflected both the fast-developing world of data science, as access to tools and capability grew quickly, and the underlying desire of our members to learn and be at the forefront of potentially exciting developments applying to their work. At that time there was clear signs of data science activity emerging in the work of General Insurance pricing.
The IFoA also recognised the need for guidance to help ensure our members applied their skills in a professional and ethical way. In 2019, in conjunction with the Royal Statistical Society, a set of ethical principles ${ }^{4}$ was published. This was followed in 2021, by more detailed ethical guidance ${ }^{5}$ from the Regulatory Board, which set out how the Code and other existing standards applied to data science work and included case studies.

From late 2022 we have observed the rapid rise of generative AI tools, becoming widely available for the first time, and rarely a day has passed since without media coverage extolling the huge advances this may bring about for humanity, or alternatively the acceleration of the end of the world. Ongoing opportunities such as greater insights on key risks, product innovation, and competitive advantage, need to be balanced with challenges around the potential for misuse of data, adverse consumer outcomes, lack of model transparency and reputational damage.

It therefore seems timely to consider where we have reached in terms of the use of data science and AI technologies by actuaries, and how our standards and guidance (and other regulatory tools) can continue to support our members.

In this report some necessary terminology is used. There are many competing descriptions in the field, which can often provoke debate. We have used language consistently with the AIan Turing Institute, the UK's national institute for data science and artificial intelligence, which has published a helpful glossary ${ }^{6}$ for some of the more common terms, and the following four in particular:

- Data science - An umbrella term for any field of research that involves the processing of large amounts of data in order to provide insights into real-world problems.
- Artificial Intelligence (AI) - The design and study of machines that can perform tasks that would previously have required human (or other biological) brainpower to accomplish. AI is a broad field that incorporates many different aspects of intelligence, such as reasoning, making decisions, learning from mistakes, communicating, solving problems, and moving around the physical world.
- Machine learning (ML) - A field of artificial intelligence involving computer algorithms that can 'learn' by finding patterns in sample data. The algorithms then typically apply these findings to new data to make predictions or provide other useful outputs, such as translating text or guiding a robot in a new setting.
- Large language model (LLM) - A type of foundation model that is trained on a vast amount of textual data in order to carry out language-related tasks. Large language models power the new generation of chatbots and can generate text that is indistinguishable from human-written text.
This report aims to provide an updated picture of the range of uses actuaries are making of these technologies. The report also provides an overview of the emerging landscape for standards and regulations relevant to data science and $\mathrm{AI}$ around the world.


## Finding 1

Increased capacity, availability, and profile of data science and $\mathrm{AI}$ tools all feeds into a rapidly changing environment. This, coupled with technological advances and ever-growing sources of data, potentially changes existing risks, and introduces new risks where such tools are adopted in areas of actuarial work.

## There is a variety of evidence showing significant involvement of actuaries in data science and AI work. This encompasses a range of domains, including examples outside traditional actuarial areas of work.

## Submissions for this review

As part of this review, we asked for submissions either on behalf of organisations, or from individuals, focusing on case studies or use cases for data science, and also views relating to governance and ethics. We also reached out to individuals with extensive experience in this field for discussions to help inform our review and findings.

We observed a range of examples across different areas of actuarial work:

- Gl personal lines pricing
- Risk management model validation
- Life insurance product modelling
- Pensions analysis of experience
- Life underwriting
- Gl claims triangles analysis.

From the review submissions, and the discussions we held, it is clear that data science usage has extended across a wider range of actuarial work. This goes significantly beyond GI pricing. Other examples of use mentioned included reporting, retention management, sales and marketing, and claims analysis.

The case studies provided by participants showed work which covers analysis of large datasets, use of machine learning techniques, and some early adoption of large language models.

## Finding 2

There is an increasing level of actuarial involvement in $\mathrm{AI}$ and data science across a range of domains, and also plans to further increase usage.

## Case Study - GI personal lines pricing

Use of new machine learning algorithms for personal lines pricing analysis.

Historically, Generalised Linear Modelling (GLM) was the go-to algorithm for actuarial pricing. These days, GLM is seen as just one of a wide range of regression / forecasting algorithms. Gradient Boosting Machines (and related techniques) have proven useful in GI so are becoming more popular for pricing actuaries to try out.

## Case Study - Trends in GI claims data

This considers general insurance claims triangles and associated claims data across firms. The claim triangles include paid claims, claim provisions held and reported but not settled claims reserves. An off-theshelf software package that uses machine learning and pattern recognition techniques identifies trends in triangle-based diagnostics consistently, quickly and across all companies and line of business.

The analysis is at an early stage but showing promise - with further work on gaining familiarity with the techniques and validating and ranking the trends identified by the software.

Case Study - Enhanced experience analysis

The Analysis of Experience for a group of UK pension schemes is based on data for active, pensioner, and dependant members at the valuation date, and movements between statuses over the inter-valuation period. The datasets include items such as date of birth, gender, date of movement, and pension amounts or salary. The traditional member experiences such as age of retirement, or post-retirement mortality are compared against previously set assumptions to determine whether the assumptions need to be updated for each scheme, which inform other valuation calculations.

The raw data is then cleaned and processed through one model to derive the 'exposure to risk' consistent with the movements and processed into a flat file aggregated format. The outputs from this model are loaded into a Python dashboard which enables rapid generation of visualisations and statistical summaries to user requirements.

Ahead of starting the next iteration of analysis the intention is to migrate the initial modelling into the $R$ statistical programming environment. This will speed up the processing and enable more rapid enhancements according to user requirements. For example, workforce dynamics, including propensity to leave service and likelihoods of taking difference levels of lump sum at retirement.

## Case Study - Model build based on

 product specification documentsGenerative $\mathrm{AI}$ is used within existing actuarial modelling software. The application uses as inputs generic and abstract product specification documents (in varying formats: PDF, MS Word, text, websites) and automatically builds actuarial models from them. Third party AI libraries are used to analyse the documents, and then proprietary software uses the analysis output and builds actuarial models.

These models then can be reviewed and further customised accordingly.

## Case Study - analysis of earnings in a loan

 portfolioA significant project providing advice, support, and analysis to support the sale of a significant and highprofile loan portfolio. One of the main models used in this project was a transitions-based Markov model, which was used to predict earnings progression of borrowers. The data for borrowers included items such as date of birth, gender, loan inception year, historical earnings, and field of work.

A sub-project was to use machine learning to analyse future earnings. The aim of this project was to understand the different predictors of earnings progression, better understand the current model's limitations and how modifications to the model can address them, using a machine learning model to test the robustness of the current model.

This made use of specialist packages within the scripting $\mathrm{R}$ language for a variety of data mining/analysis techniques. In particular, random forests were chosen to model earnings progression. Feature importance testing from random forests was used to understand which predictors were driving earning progression. A model using random forests to project earnings of borrowers and a comparison framework were built, that would allow comparison of results against the current model.

The robustness of the current model was affirmed, including identifying potential improvements that could be made, and the comparison framework was taken forward for future model testing.

## Case Study - Life underwriting

Applications for life cover are initially assessed using a rules-based process that allows $75 \%$ of customers to be given an immediate decision on cover. The remaining $25 \%$ of applications would traditionally be referred to an underwriter for review. A suite of machine learning models has been developed to predict underwriting decision, based on customer, policy and high level medical and family history disclosure data gathered at the point of application.

Each model within the suite takes an ensemble learning approach (random forest) and multiple models are combined to predict underwriting decision. The application of the models is refined to optimise risk cost loading and decision profile across the application.

The population to which the models are applied is defined by a set of rules based on current underwriting philosophy. The model has been in production for five years and is well established.

## Case Study - processing large volumes of unstructured text

Developing a model to process large quantities of unstructured datasets in the form of reports and other text-heavy inputs. Naturally, this is a time-consuming and resource-intensive activity, especially with ever-growing datasets of increasing complexity. Enhancing the ability to remain on top of this to maintain an accurate picture has therefore become an important priority.

With the emergence of deep learning-based language models, a semantic search system has been built to help retrieve information by simply 'asking' in plain English. Semantic search is a deep learning-based system that enables the machine to 'understand' the context and meaning behind users' requests, allowing the machine to retrieve contextually relevant information to users. This approach goes beyond traditional keywordmatching/rules-based approaches, capable of dealing with the variability, ambiguity, and complexity of natural language.

The system is currently in user acceptance testing phase, based on an experimental version of the application.
The range of applications is increasing, beyond GI pricing, into other traditional actuarial areas of work. There is also some evidence of emerging involvement of actuaries in wider fields. Participants in the review remarked there may be challenges in ensuring standards and guidance remain proportionate and appropriate to the growing applications of data science and AI where actuaries may apply their skills.

## Ethics and fairness considerations

We asked participants about considerations and challenges on terms of ethical and fair use of data science and AI. It was clear that ethical considerations are a priority and seen as a vital aspect of data science and AI development and use.

Responses and discussion points included the following:


#### Abstract

"Subject Matter Experts and key stakeholders are discussing how to standardise the approach to ethics and fairness across all teams doing data science (including actuaries and non-actuaries). The solutions will include clear definitions to ensure everyone is on the same page, and where relevant point to existing internal policies and controls which already touch on related matters (even if not explicitly labelled as ethics historically)."


'For actuarial profession members, the Actuaries' Code and existing guidance on ethical data science puts us in a strong position, though clearly for firms where a mix of professions and roles are involved in data science, firms will need a consistent internal approach."[^0]

"Ethics and fairness are considered at two main points of the development process for all machine learning models. Firstly, at the outset of the development work and then again prior to implementation. Fairness and ensuring an unbiased sample are key considerations. If any inappropriate bias is found the model would be redeveloped removing the relevant characteristic and assessed again before implementation."

"The key ethical and fairness challenges associated with data science are ensuring personal data are appropriately protected, dealing with lack of data at a demographic and national level, and demonstrating professional competence."

"In terms of demonstrating professional competence, the organisation is committed to producing high quality analysis, is accredited under the IFoA's Quality Assurance Scheme and complies with all relevant professional standards (such as the FRC's TASs)."

"There should be a framework in place to help users tackle bias and fairness challenges. This should look to go beyond just identifying the challenges and seek to put clear actionable guidance in place. Other aspects to consider are discrimination-free pricing and explainability of models and techniques."

The responses show that actuaries, and their organisations, see ethics and fairness as critical aspects to consider for data science and AI. The feedback encompassed data privacy, tackling bias, demonstrating competence, and that actuaries will often be working with other professionals, which may have an impact on the application of ethical considerations. In wider discussions participants also highlighted the significant professional and reputational risks associated with potential misunderstanding and misuse of new AI techniques, with a view that specific AI-targeted standards may be required to mitigate this.

There are of course other stakeholders with views on ethics and fairness, consumers and regulators being two important examples. Additionally, views of what constitutes ethical and fair behaviour are rarely uniform, and this will especially be the case for global developments.
Often actuaries will be working alongside data scientists, and other experts, with organisations being more focused on relevant skills than professional qualifications. This may bring challenges in maintaining demand for actuaries in certain types of work, at a time where there is increasing demand from employers to use data science and $\mathrm{AI}$ techniques.

## FRC and GAD Research - the use of AI and ML in UK actuarial work

In the first half of 2023, the UK Government Actuary's Department (GAD) carried out a survey on behalf of the FRC, focused on the use of AI or ML techniques by actuaries working in the UK. The findings from this were reported ${ }^{7}$ in October 2023, with key highlights set out below:

- The main use of AI/ML techniques in UK actuarial work relates to insurance pricing, particularly in General Insurance, with use being more limited in other areas.
- Governance and quality assurance processes are generally being informally adapted for models using $\mathrm{AI} / \mathrm{ML}$ techniques.
- The research suggests that explainability is a key factor in the choice of modelling techniques and tended to be a greater challenge for $\mathrm{AI} / \mathrm{ML}$ models than for established modelling techniques.
- A key risk highlighted by those using AI/ML techniques was that of bias or potential discrimination, either as a result of the modelling techniques used, or bias in the underlying data.
- The recent proliferation of LLMs has had a rapid and potentially significant impact on actuarial work. This highlights the risk of adopting new technical advances when they may not be fully understood.


## Conference and CPD sessions

Both IFoA members, and other international actuaries, have presented sessions, or authored papers, on a range of relevant topics. In this report we focus on examples from 2023 to provide an overview of the extensive material from this source.

Case studies are provided below with a wider set of examples provided in Appendix 4.

Case Study - Use ML and AI to model lapses and draw insights

Lapse rates is one of the main risk drivers for many life and health products and a key assumption for pricing, reserving, asset-liability modelling, and risk management. Despite being influenced by many factors, lapse rare modelling has in the past been relatively crude. A working party considered various machine learning techniques and demonstrated how explainable $\mathrm{AI}$ can be applied to model outputs to gain further insights. Comparisons to existing lapse models shows pros and cons of adopting these new techniques.

Case Study - Building a capital model in an open-source framework

Using open-source software to build a capital model is a problem that has not been widely tackled across the industry. The majority of capital models are built in proprietary software and can be relatively 'black box' in their nature.

This session covered:

- how an actuary with no coding experience built a capital model from scratch, primarily using a large language model
- how much insight into capital modelling can be gleaned by simply posing the right questions to a large language model
- showcasing the results of this experiment in an easy-to-build, user-friendly dashboard to give an understanding of the approach
- discuss the potential enhancements and improvements to make and what a development roadmap could look like.
Case Study - AI and ML as opportunities to improve insurance penetration in Africa

Unfavourable weather conditions and natural disasters pose a significant risk to the predictability of income for farmers. Weather index-based crop insurance based on big data from farmers and satellites, means that a practical solution is possible in enhancing the resilience of farmers to weather related shocks thereby enhancing food security. Weather index-based insurance is less expensive to administer compared to traditional insurance hence more affordable contracts and faster payments to farmers, who often need the funds for timely planting in the subsequent season. The research aims to enhance de-risking small scale farmers by reducing the costs associated with crop insurance, thereby increasing the uptake of the product. This is achieved using $\mathrm{AI}$ and $\mathrm{ML}$ algorithms applied on the available big data.

The sessions cover a wide range of domains and topics, and it is clear that actuaries are considering both technical and ethical aspects. AIthough some of the areas of work may be less advanced in practice than others, it is important that ongoing support for actuaries to develop in data science and AI recognises that wider application has started and is likely to expand in coming years.

## Further IFoA member-driven activity

There are several IFoA community-led workstreams and working parties looking at a range of data science and AIrelated topics, including the examples below.

## - Data Science Community

- Various workstreams including research, collaboration, regulation and ethics, education and lifelong learning
- Risk Management: AI Ethics working party
- GI: Machine Learning in Reserving working party
- Health \& Care: Techniques in Data Science working party
- Life: Artificial Intelligence and Automation working party.

These groups produce a range of materials, which include articles, papers, surveys and webinar and conference sessions.

Additionally, during 2023, the latest edition of the IFoA

Longevity Bulletin ${ }^{8}$ was dedicated to the use of data science and machine learning in mortality analysis. This covered a range of problems and techniques, illustrating where a traditional area of actuarial work can benefit from the opportunities of data science and $\mathrm{AI}$.

## Conclusion 1

There is considerable change and activity from a global regulatory perspective, with further developments expected to focus on responsible and ethical use of emerging technologies. This provides important context for the IFOA and other regulators in considering actions which continue to provide clear expectations and support to actuaries working in this domain. There will be challenges in ensuring standards and guidance remain proportionate and relevant to the growing applications of data science and AI where actuaries may apply their skills, whilst recognising the changing risk landscape.

## Standards and regulations

## Existing standards and regulations

Before considering any specific emerging AI standards and regulation, in many jurisdictions there already exists relevant legislative and regulatory elements which cover activities and outcomes from data science and AI work. In conducting work in this field actuaries, and their organisations, will have conduct and prudential standards and regulations that they must follow. This may cover areas such as:

- consumer protection and fair treatment
- data management and privacy
- model management and validation
- wider governance requirements for firms, including robust risk management processes.


## IFOA regulatory material

From an IFoA perspective, the Actuaries' Code must be followed by members, and as previously mentioned, additional specific data science guidance was published in 2021. Two of the most relevant principles of the Code worth highlighting in a data science and $\mathrm{AI}$ context are:

- Principle 2 of the Code which states "Members must carry out work competently and with care" and "must ensure that they have an appropriate level of relevant knowledge and skill to carry out a piece of work."
- Principle 6 of the Code states that "Members must take reasonable steps to ensure that any communication for which they are responsible or in which they have a significant involvement is accurate, not misleading, and contains an appropriate level of information."

In September 2023 the IFoA published a Risk AIert ${ }^{9}$, reminding members of some key risks around the use of data science and $\mathrm{AI}$, and highlighted possible new risks given the heightened recent developments. In the UK, existing FRC technical standards are likely to apply to the majority of work by actuaries in this domain, with the recently updated TAS $100^{10}$ and accompanying model guidance ${ }^{11}$ most relevant, with the latter document making direct reference to emerging $\mathrm{AI}$ and ML models within its scope. For non-UK members, recognised standards in the relevant jurisdictions will apply, to the extent that consistency is achieved with the requirements of International Actuarial Association ISAP 12.

Finding 5

The IFoA, and other actuarial regulators, already have standards and guidance in place which is relevant to data science and AI work. There is a balance to strike between specific standards to ensure the safe and responsible use of $\mathrm{AI}$ by actuaries, and amendments to existing professional and ethical guidance material. There is a risk that setting specific standards will be overtaken by events, given the ongoing high-paced development of data science and $\mathrm{AI}$.

## A global outline of emerging standards and regulation for $\mathrm{AI}$ (up to end 2023)

In recent years, the focus of directly relevant AI material published by regulators around the world has been on principles, frameworks, and guidance, with much less on specific standards and regulation to date. In common with technical developments seen in the last year, there is also a wide range of global regulatory initiatives taking place, with some early signs of how standards and regulation will develop for data science and AI.

Amongst the range of proposals, there is differing weights put on safety and innovation. There are however a number of emerging common themes, and some welcome coalescing around the need for an emphasis on safe, responsible, and transparent use of AI.

Looking more closely at what has been developing around the globe, we can observe both similarities and differences, with the pace of change also not the same.

<img src="https://cdn.mathpix.com/cropped/2024_04_02_556b9fff27797a776798g-15.jpg?height=182&width=922&top_left_y=2509&top_left_x=196" alt="image" style="width:100%;height:auto;">

The UK is attempting to place itself front and centre of developments in AI, with supporting activity in the regulation space. This is still mainly at the stage of gathering information from discussion papers, and the UK government has indicated it plans to take a 'pro-innovation' approach.

The EU was relatively quick off the blocks with its AI Act. AIthough this was adopted by the EU Parliament in June 2023, it then went through the more difficult stage of individual member country approval, with Parliament and Council reaching a provisional agreement in December 2023. The Act as it stands is seen as being at the stricter end of potential regulation with aspects covering:

- Safeguards agreed on general purpose artificial intelligence
- Limitation for the of use biometric identification systems by law enforcement
- Bans on social scoring and AI used to manipulate or exploit user vulnerabilities
- Right of consumers to launch complaints and receive meaningful explanations.
The Monetary Authority of Singapore (MAS) has taken the approach of liaising with financial services industry representatives to collaborate on toolkit material, and key themes for an upcoming whitepaper.

In the US, there is a mix of activity across regulatory and governmental agencies, the Senate, and the Executive. For the latter, the executive order provides a glimpse into how US regulations might go, although this may be impacted by political developments in 2024.

As a key player in AI, China has already put elements of specific regulation into place, covering aspects that are relevant to $\mathrm{AI}$ development and use, and is thus one of the few jurisdictions that has gone beyond principles and frameworks.

## There is evidence of international co-operation and

collaboration, with the Organisation for Economic Co-operation and Development (OECD) having principles in place since 2019, and more recent developments such as the Bletchley Agreement.

The table below summarises examples of activity observed in key territories.

## Country/Territory

## Key developments

UK

- PRA/FCA discussion paper ${ }^{13}$ and feedback statement ${ }^{14}$
- Government white paper ${ }^{15}$
- Centre for Data Ethics and Innovation

AI standards hub

| European Union | - AI Act ${ }^{16}$ |
| :---: | :---: |
| China | - Ethical Norms for New Generation Artificial Intelligence ${ }^{17}$ |
|  | - Measures for the Management of Generative Artificial Intelligence Services ${ }^{18}$ |
| India | - Telecoms regulator paper ${ }^{19}$ |
| Singapore | MAS - toolkit for responsible use of $\mathrm{AI}^{20}$ <br> and planned whitepaper on generative $\mathrm{AI}$ risk framework ${ }^{21}$ |
| US | - NAIC Principles on $\mathrm{AI}^{22}$ |
|  | - Bipartisan Framework for U.S. AI Act ${ }^{23}$ |
|  | - White House AI executive order ${ }^{24}$ |
| Australia | - AI ethics principles 25 |
| Global | - OECD AI Principles |
|  | - Bletchley Declaration |
|  | - Guidelines for Secure AI System Development 26 |

References from the previous page:
| DP5/22 - Artificial Intelligence and Machine Learning
FS2/23 - Artificial Intelligence and Machine Learning
| DSIT - A pro-innovation approach to AI regulation
| EU Artificial Intelligence Act: deal on comprehensive rules for trustworthy AI
Chinese government - Ethical Norms for New Generation Artificial Intelligence
Chinese government - Measures for the Management of Generative Artificial Intelligence Services
Leveraging Artificial Intelligence and Big Data inTelecommunication Sector
| MAS - Toolkit for Responsible Use of AI in the Financial Sector
| MAS - Generative AI Risk Framework for the Financial Sector
| NAIC - Principles on Artificial Intelligence
Bipartisan Framework for U.S. AI Act Senator Richard Blumenthal \& Senator Josh Hawley
| Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence
| Australia's AI Ethics Principles
| UK National Cyber Security Centre (NCSC), the US Cybersecurity and Infrastructure Security Agency (CISA)

## Finding 6

There has been and continues to be extensive regulatory activity around the globe, although still at different stages and pace of action. 2024 is likely to see further developments and in certain jurisdictions a move from principles-based guidance to more formal regulation.

It is worthwhile exploring some of the emerging common themes that can be observed across the different jurisdictions:

## Emerging common themes

| Robustness, Security |  |
| :--- | :--- |
| and Safety | - Understanding, prevention, and mitigation of potential physical and ethical harms |
| Governance and <br> Accountability | - Ensuring proper functioning of process and systems |
| Fairness and Ethics | - Avoiding preference or prejudice towards groups or characteristics |
|  | - Ability to look at workings of model and understand decisions |
| Transparency, challenge, and standards. <br> Explainability and <br> Interpretability | Reasoning for decisions and predictions readily understood |

There are, of course, other similar themes across the material published so far, and alternative ways of describing them. What will be key is how these themes are expanded upon in order to provide clear and practical guardrails for users to operate within, and also the extent to which international consistency emerges in any formal regulatory implementations. There may be differing approaches taken, depending on the extent to which specific AI regulations are deemed necessary, as opposed to guidance attached to existing general regulation (such as consumer protection, privacy, model risk management for example).

A key consideration may also be to what extent the types of models, and use, suggests lesser or greater challenges with respect to these themes. There may be less need for prescriptive regulatory material in relation to narrow uses, or use of well-established and understood, trustworthy models and techniques, whereas newer developments where there is less established knowledge and validation may need greater attention, for example, generative $\mathrm{AI}$ and large language models.

## Conclusion 2

There is also considerable change and activity from a global regulatory perspective, with further developments likely during 2024. This provides important context for the IFOA and other regulators in considering actions which continue to provide clear expectations and support to actuaries working in this domain. There will be challenges in ensuring standards and guidance remain proportionate and relevant to the growing applications of data science and AI where actuaries may apply their skills, whilst recognising the changing risk landscape.

## Learning and collaboration

## Lifelong Learning

In recent years the IFoA has developed both the assessment curriculum and lifelong learning material to cover developments in data science and associated modelling techniques.

At present the qualification pathway covers aspects of data science and $\mathrm{AI}$ related techniques in a number of places:

- Actuarial Statistics - students are introduced to large data sets, machine learning, and software packages that can be used to produce analysis
- Specialist Principles - where data science applications in certain domains are explored

Specialist Advanced - the ethical and regulatory aspects are outlined in this part of the curriculum.

For some years, the IFoA, in conjunction with University of Southampton, offered the Certificate in Data Science, as a high-level introduction to key concepts and methods, aimed at qualified members who wanted to develop knowledge in this field.

The IFoA continues to review its education and lifelong learning offering for members, with a view to ensuring they are wellequipped to tackle the opportunities of data science and AI. There is a risk to the profile of the profession if learning resources and opportunities do not keep up with the pace of change.

Finding 7

At present there is material in parts of the underlying core curriculum for students. Additionally, there have been lifelong learning opportunities, for example through the IFoA Data Science certificate. There are current plans to develop both of these strands to help ensure our members continue to be well-placed to contribute to this field.

## Opportunities for collaboration and helpful information sources

There are a number of organisations or agencies who may have common aims and goals to the IFoA, and where refreshed or new collaborations could help our members further thrive in data science and AI. This encompasses organisations such as professional bodies (including other actuarial associations), national and international institutes, government agencies and regulators.

There is also a huge range of material that actuaries can reference to learn more about this topic, and to find about the range of views there are on how data science and $\mathrm{AI}$ might develop, including risks and concerns.

In the table below there are examples where fellow actuarial associations have published material relevant to data science and $\mathrm{AI}$ in recent times. Additionally, there are papers and materials from a range of international agencies. This is an excellent source of information covering key issues and additionally principles to follow in its use. This provides opportunities for learning and collaboration, especially important given the global implications and influence of AI development.

## Finding 8

The IFoA has previously collaborated successfully with stakeholders in this field. There exist wide-ranging opportunities to continue this, seeking out new avenues to influence future paths for data science and AI. There are a wide range of materials and sources available to actuaries to learn more and seek views on this topic.

| Source | Data science / AI material |
| :--- | :--- |
| Society of Actuaries (US) | - Ethical Use of Artificial Intelligence for Actuaries ${ }^{27}$ |
| Actuaries Institute (Australia) | - Artificial intelligence and discrimination in insurance pricing and underwriting ${ }^{28}$ |
| Actuarial Association of Europe | - AI and the opportunities and challenges it presents to insurability ${ }^{29}$ |
| International Actuarial Association (IAA) | Actuaries and Data Science 2020 survey summary 30 |
| World Economic Forum | - AI Governance AIliance |
| OECD | - How can we ensure AI benefits society as a whole? |
| Royal Statistical Society (UK) | D The UK's national institute for data science and artificial intelligence |
| The AIan Turing Institute (UK) |  |

[^1]
## Findings and conclusions

## A full list of our findings is given in the table below. These are set out in the order they appear in this report.

## Findings

<img src="https://cdn.mathpix.com/cropped/2024_04_02_556b9fff27797a776798g-21.jpg?height=599&width=1762&top_left_y=874&top_left_x=158" alt="image" style="width:100%;height:auto;">

4 Often actuaries will be working alongside data scientists, and other experts, with organisations being more focused on relevant skills than professional qualifications. This may bring challenges in maintaining demand for actuaries in certain types of work, at a time where there is increasing demand from employers to use data science and $\mathrm{AI}$ techniques.

5 There has been and continues to be extensive regulatory activity around the globe, although still at different stages and pace of action. 2024 is likely to see further developments and in certain jurisdictions a move from principlesbased guidance to more formal regulation.

The IFoA, and other actuarial regulators, already have standards and guidance in place which is relevant to data science and $\mathrm{AI}$ work. There is a balance to strike between specific standards to ensure the safe and responsible use of $\mathrm{AI}$ by actuaries, and amendments to existing professional and ethical guidance material. There is a risk that setting specific standards will be overtaken by events, given the ongoing high-paced development of data science and AI.

7 At present there is material in parts of the underlying core curriculum for students. Additionally, there have been lifelong learning opportunities, for example through the IFOA Data Science certificate. There are current plans to develop both of these strands to help ensure our members continue to be well-placed to contribute to this field.

8 The IFoA has previously collaborated successfully with stakeholders in this field. There exist wide-ranging opportunities to continue this, seeking out new avenues to influence future paths for data science and AI. There are a wide range of materials and sources available to actuaries to learn more and seek views on this topic.

## Conclusions

No Conclusions

1 The increasing use of data science and AI, and the demand for relevant skills, presents continuing opportunities for actuaries. To remain competitive actuaries will need evolving resources covering professional development and standards to support them as builders or users of AI systems and outputs.

There is considerable change and activity from a global regulatory perspective, with further developments expected to focus on responsible and ethical use of emerging technologies. This provides important context for the IFOA and other regulators in considering actions which continue to provide clear expectations and support to actuaries working in this domain. There will be challenges in ensuring standards and guidance remain proportionate and relevant to the growing applications of data science and AI where actuaries may apply their skills, whilst recognising the changing risk landscape.

## Appendix 1 - Scope and approach

We launched this review in June 2022 with the following scope:

## Data Science

Data science covers a range of techniques used to analyse and model large and diverse sources of data. This may include the use of complex modelling techniques, such as machine learning, across a range of programming platforms.

This exercise will gather information and case studies on the range of ways data science is developed and used by actuaries across different practice areas and work functions, both in and outside the UK. It will also seek to gather such information in wider fields and new domains

Beyond the headline scope, our focus has also been on the emerging standards and regulation being proposed or applied to data science and AI work. We commenced our review in July 2023.

The IFoA website provides more information on the work of the AMS Team.

## Review methodology

The review was carried out in a number of ways:

- Collecting information from organisations and individuals through a review questionnaire
- Asking for examples of material produced by actuaries
- Researching the business and regulatory environment
- A high-level review of the current actuarial education and lifelong learning material relevant to data science
- Follow-up interviews with actuaries at participating organisations to understand the context of the questionnaire responses and any work examples received
- Further interviews with individuals knowledgeable in this field.

During the review an interim discussion session was held with the IFoA Regulatory Board in July 2023, when a range of relevant issues were covered. As a result of this the IFOA issued a Risk AIert in September 2023 whilst review work was ongoing.

## Submissions and participation

We would like to thank the following organisations and individuals for their support and participation in our review:

- Government Actuary's Department (UK)
- Prudential Regulation Authority
- Green 13
- Royal London
- Matthew Byrne
- Valerie Du Preez
- Chris Dolman
- Ronald Richman
- Richard Galbraith

<img src="https://cdn.mathpix.com/cropped/2024_04_02_556b9fff27797a776798g-24.jpg?height=145&width=1574&top_left_y=253&top_left_x=138" alt="image" style="width:100%;height:auto;">

| Ref No. | Title | Author | Description |
| :---: | :---: | :---: | :---: |
| 1 | The Actuaries' Code | IFoA | The ethical Code of Conduct that all members of the <br> IFoA must follow |
| 2 | Standard Setting at the IFoA (2020) | IFoA | Information about the Standards Framework and the <br> principles that inform standard setting at the IFoA |
| 3 | APS X2 - review of actuarial work | IFoA | Actuarial professional standard setting out types of <br> review to be applied to actuarial work |
| 4 | A Guide for Ethical Data Science | IFoA/RSS | A set of ethical principles for data science |
| 5 | Ethical and professional guidance on Data <br> Science | IFoA | Guidance setting out how actuarial standards apply <br> in data science work |
| 6 | Data Science and AI Glossary | AIan Turing <br> Institute | Key AI and data science terms |
| 7 | Research on the use of Artificial <br> Intelligence and Machine Learning in UK <br> actuarial work | FRC | Paper setting out findings from research |
| 8 | Longevity Bulletin 15: The machine <br> learning issue | IFoA | Publication outlining uses of machine learning for <br> mortality and longevity work |
| 9 | Risk alert: The development and use of AI <br> techniques and outputs by actuaries | IFoA | Non-mandatory guidance on AI for IFoA members |
| 10 | Technical Actuarial Standard 100: General <br> Actuarial Standards | FRC | General technical standards for UK actuarial work |
| 11 | Technical Actuarial Guidance: Models | FRC | Additional technical guidance on model use |
| 12 | ISAP 1 - General Actuarial Practice | IAA | General international actuarial standard |
| 13 | DP5/22 - Artificial Intelligence and <br> Machine Learning | PRA | UK regulatory discussion paper |
| 14 | FS2/23 - Artificial Intelligence and <br> Machine Learning | PRA | UK regulatory feedback statement |
| 15 | DSIT - A pro-innovation approach to AI <br> regulation | UK <br> Government | UK white paper on AI regulation |


| Ref No. | Title | Author | Description |
| :---: | :---: | :---: | :---: |
| 16 | Artificial Intelligence Act: deal on <br> comprehensive rules for trustworthy AI | EU | EU AI regulation |
| 17 | Ethical Norms for New Generation <br> Artificial Intelligence | Chinese <br> Government | Example of Chinese regulation on use of $\mathrm{AI}$ |
| 18 | Measures for the Management of <br> Generative Artificial Intelligence Services | Chinese <br> Government | Example of Chinese regulation on use of $\mathrm{AI}$ |
| 19 | Leveraging Artificial Intelligence and Big <br> Data in Telecommunication Sector | India Telecoms <br> Regulator | Example of Indian regulation on use of AI |
| 20 | Toolkit for Responsible Use of AI in the <br> Financial Sector | MAS | Example of AI regulatory activity in Singapore |
| 21 | Generative AI Risk Framework for the <br> Financial Sector | MAS | Example of AI regulatory activity in Singapore |
| 22 | Principles on Artificial Intelligence | NAIC | Key AI regulatory principles from the US insurance <br> regulator |
| 23 | Bipartisan Framework for U.S. AI Act | Senators <br> Richard <br>  <br> Josh Hawley | Framework document for potential US AI regulation |
| 24 | Executive Order on the Safe, Secure, and <br> Trustworthy Development and Use of <br> Artificial Intelligence | The White <br> House | Sets out direction of travel for potential US AI <br> regulation |
| 25 | Australia's AI Ethics Principles | Australian <br> Government | Key principles for the use of $\mathrm{AI}$ |
| 26 | Guidelines for Secure AI System <br> Development | UK NCSC, US <br> CISA | Guidelines on AI development set out by the UK <br> National Cyber Security Centre and US Cybersecurity <br> and Infrastructure Security Agency |
| 27 | Ethical Use of Artificial Intelligence for <br> Actuaries | Society of <br> Actuaries | Paper setting out guidance on ethical use of $\mathrm{AI}$ |
| 28 | Artificial intelligence and discrimination <br> in insurance pricing and underwriting | Actuaries <br> Institute and <br> Australian <br> Human Rights <br> Commission | Paper highlighting risks of $\mathrm{AI}$ in insurance pricing |
| 29 | AI and the opportunities and challenges it <br> presents to insurability | AAE | Paper discussing risks and opportunities of $\mathrm{AI}$ in <br> insurance |
| 30 | Actuaries and Data Science 2020 survey <br> summary | IAA | Report prepared by the Big Data Working Group of <br> the IAA |

## Appendix 3 - Abbreviations

| Abbreviation | Full term |
| :---: | :---: |
| AAE | Actuarial Association of Europe |
| $\mathrm{AI}$ | Artificial Intelligence |
| FRC | Financial Reporting Council |
| GAD | Government Actuary's Department |
| Gl | General Insurance |
| GLM | Generalised Linear Model |
| IAA | International Actuarial Association |
| IFoA | Institute and Faculty of Actuaries |
| LLM | Large Language Model |
| MAS | Monetary Authority of Singapore |
| ML | Machine Learning |
| NAIC | National Association of Insurance Commissioners |
| OECD | Organisation for Economic Collaboration and Development |
| PRA | Prudential Regulatory Authority |
| RSS | Royal Statistical Society |
| TAS | Technical Actuarial Standard |

## Appendix 4 - Examples of conference topics

Generative AI: the biggest transformation since desktop computing

AIternative data in Life and health risk assessment

Lapse in judgement - use ML and XAI to model lapses

AIexa, build my Actuarial model

From Bias to Black Boxes - managing and understanding the risks of $\mathrm{AI}$

Why isn't machine learning more transparent in personal lines pricing?

How can actuaries best add value to claims?

Can we build a capital model in an open-source framework from scratch?

Managing AI risks in insurance

IFoA GIRO 2023

Actuarial data science - innovative approaches and best practices

Two worlds colliding: the role of pricing actuaries amongst data scientists

Smoothness and monotonicity constraints for neural networks

Socially responsible insurance in the age of $\mathrm{AI}$

$\mathrm{AI}$ and $\mathrm{ML}$ as opportunities to improve insurance penetration in Africa:

Case of small-scale farmers in Kenya and Ghana

An initial approach to optimizing insurance quotes with quantum computing

IAA International Congress of Actuaries 2023

Machine Learning to Predict Underwriting Decisions for Life and Health Insurance

Application of Reinforcement Learning to Dynamic Hedging of Variable Annuities

DISCLAIMER: The views expressed in this publication are those of invited contributors and not necessarily those of the Institute and Faculty of Actuaries. The Institute and Faculty of Actuaries do not endorse any of the views stated, nor any claims or representations made in this publication and accept no responsibility or liability to any person for loss or damage suffered as a consequence of their placing reliance upon any view, claim or representation made in this publication. The information and expressions of opinion contained in this publication are not intended to be a comprehensive study, nor to provide actuarial advice or advice of any nature and should not be treated as a substitute for specific advice concerning individual situations. On no account may any part of this publication be reproduced without the written permission of the Institute and Faculty of Actuaries.

## Beljing

Room 512 $\cdot$ 5/F Block A $\cdot$ Landgentbldg Center $\cdot$ No. 20 East Middle 3rd Ring Road Chaoyang District $\cdot$ Beijing $\cdot 100022 \cdot$ People's Republic of China

Tel: +861058783008

## London (registered office)

1-3 Staple Inn Hall $\cdot$ High Holborn London $\cdot$ WCIV 7QJ

Tel: $+44(0) 2076322100$

## Malaysia

Arcc Spaces $\cdot$ Level 30 . Vancouver suite $\cdot$ The Gardens North Tower Tel: +60125913032

## Oxford

Belsyre Court $\cdot$ ist Floor 57 Woodstock Road-Oxford OX2 6HJ Tel: +44 (0) 2076322100[^2]

## Singapore

Pacific Tech Centre $\cdot$ 1 JIn Kilang Timor $\cdot$ \#06-01 $\cdot$ Singapore $\cdot 159303$ Tel: +6587781784


[^0]:    "The main challenge is to ensure data security and compliance to GDPR related rules. Examples to support this include:

    - use reputable AI organisations who already comply with related data protection rules
    - use private instances of AI or LLM for clients who have them set up."

[^1]:    | Society of Actuaries - Ethical Use of Artificial Intelligence for Actuaries (2019)

    Actuaries Institute and Australian Human Rights Commission (2022)

    AAE Discussion Paper

    Report prepared by the Big Data Working Group (BDWG) of the IAA (2021)

[^2]:    dstock R

