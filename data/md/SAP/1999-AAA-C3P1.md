# Phase I Report of the American Academy of Actuaries' C-3 Subgroup of the Life Risk Based Capital Task Force to the National Association of Insurance Commissioners' Risk Based Capital Work Group 
October 1999 - Atlanta, GA 

The American Academy of Actuaries is the public policy organization for actuaries practicing in all specialties within the United States. A major purpose of the Academy is to act as the public information organization for the profession. The Academy is nonpartisan and assists the public policy process through the presentation of clear and objective actuarial analysis. The Academy regularly prepares testimony for Congress, provides information to federal elected officials, comments on proposed federal regulations, and works closely with state officials on issues related to insurance. The Academy also develops and upholds actuarial standards of conduct, qualification and practice and the Code of Professional Conduct for all actuaries practicing in the United States.

This report was prepared by the American Academy of Actuaries Life Risk-based Capital Task Force.

**C-3 Subgroup of the Life Risk-Based Capital Task Force**

    Robert A. Brown, F.S.A., M.A.A.A., Chair
    Errol Cramer, F.S.A., M.A.A.A.
    Craig Fowler, F.S.A.
    Alastair Longley-Cook, F.S.A., M.A.A.A.
    Linn K. Richardson, F.S.A.,M.A.A.A.
    David K. Sandberg, F.S.A., M.A.A.A.
    James A. Tolliver, F.S.A., M.A.A.A.
    Michael L. Zurcher, F.S.A., M.A.A.A.
    Joseph L. Dunn, F.S.A., M.A.A.A
    Glenn Keller, F.S.A., M.A.A.A.
    James F. Reiskytl, F.S.A., M.A.A.A.
    Mark C. Rowley, F.S.A., M.A.A.A.
    Stephen A.J. Sedlak, F.S.A., M.A.A.A.
    Bill Wilton, F.S.A., M.A.A.A.

## Table of Contents - C3 Phase 1

    I. Acknowledgements - Page 3
    II. Executive Summary - Pages 4-6
    III. Appendix I - Scenario Testing Methodology - Pages 7-9
    IV. Appendix II - Frequently Asked Questions - Page 10-11
    V. Appendix III - Technical Aspects of the Scenario Generator and the Scenario Selection Process - Pages 12-15
    VI. Appendix III, Section A - Page 16
    VII. Appendix III, Section B - Page 17-19
    VIII. Appendix III, Section C - Page 20
    IX. Appendix IV, C-3 Pilot Testing: Results from the " 50 " Scenario Subset - Pages 21-23
    X. Draft Instructions

## Acknowledgements - C3 Phase 1

In addition to the members of the Academy's C-3 Subgroup, contributing to the report were Ron Rubnich, Steve Ekblad, and Lloyd Spencer. Their efforts are greatly appreciated. Also, thanks is due to the full Life Risk Based Capital Task Force at the Academy for their efforts.

## Executive Summary - C3 Phase 1
**Background**

Several years ago, the NAIC Life Risk Based Capital Working Group asked the AAA Life Risk Based Capital Task Force to take a fresh look at the C-3 component of the RBC formula to see if a practical method could be found to reflect the degree of asset/liability mismatch risk of a particular company.

We reviewed the request and we agree that more sensitivity to the specifics of product design and funding strategy is appropriate to advance the goal of differentiating weakly capitalized companies from the rest. We have determined that, due to the widespread use of increasingly well disciplined scenario testing for Asset Adequacy Analysis, a foundation now exists for such an improvement. For this purpose, we have defined C-3 risk to include Asset/Liability risk in general, not just interest rate risk. However, this recommendation does not address refining the measurement for other than interest rate risk, since doing so would require introduction of a model of stock market performance. Addressing these products is one of the "next steps" suggested.

Our recommendation is to change the method of developing the C-3 component of RBC, effective $12 / 31 / 2000$, building on the work of the asset adequacy modeling, but using interest scenarios designed to help approximate the $95^{\text {th }}$ percentile C-3 risk.

**Recommendation**

The revised C-3 component is to be calculated as the sum of three amounts, but subject to a minimum and maximum. The calculation is:

a) For Annuities or Single Premium Life Insurance products, whether written directly or assumed through reinsurance, that the company tests for Asset Adequacy Analysis using cash flow testing, the C-3 requirement is calculated based on the same cash flow models, assets, and assumptions used and same "as-of" date as for Asset Adequacy, but with a different set of interest scenarios, and a different measurement of results. A weighted average of a subset of the scenario specific results is used to determine the $\mathrm{C}-3$ requirement. If the "as-of" date of this testing is not $12 / 31$, the ratio of the $\mathrm{C}-3$ requirement to reserves on the "as-of" date is applied to the year end reserves, similarly grouped, to determine the year-end C-3 requirement for this category. With respect to reinsured ceded or assumed business, Asset Adequacy Analyses should be based on the risk actually retained or assumed, and reflect expected experience rating and other adjustments based on the scenarios tested. Equity indexed products are to use the existing factors, not the results of scenario testing.  

b) For all other products (either non-cash-flow-tested or those outside the product scope defined above) the $\mathrm{C}-3$ requirements are calculated using current existing factors and instructions.

c) For callable assets (including IOs and similar investments) supporting untested products and surplus the C-3 requirement is $50 \%$ of the excess, if any, of statement value above current call price (calculated on an asset by asset basis).

The total C-3 component is the sum of $\mathrm{a}, \mathrm{b}$, and $\mathrm{c}$, but not less than half nor more than double the $\mathrm{C}-3$ component based on current factors and instructions.

- For this recommendation, "annuities" means products with the characteristics of deferred and immediate annuities, structured settlements, guaranteed separate accounts, and GICs (including synthetic GICs, and funding agreements). If cash flow testing of debt incurred for funding an investment account is required by the insurer's state of domicile for asset adequacy analysis, it is included. Equity based variable products are not to be included, but products that guarantee a bond index and variable annuities sold as fixed are, if they are cash flow tested.
- The company may use either a standard 50 scenario set of interest rates or an alternative, but more conservative, 12 scenario set (for part a, above). It may use the smaller set for some products and the larger one for others, but aggregation will then only be available among products using the same scenario sets. Details of the scenario testing methodology are contained in Appendix I.
- In order to allow time for the additional work effort needed for the new approach while not delaying filing dates, we recommend that an estimated value be permitted for the year end statement. For the RBC diskette filing, these C-3 results must be determined by scenario. If the actual $\mathrm{RBC}$ value exceeds that estimated earlier in the blanks filing by more than $5 \%$, or if the actual value triggers regulatory action, a revised filing of that statement page with the NAIC and the state of domicile is required by June 15 , otherwise it is permitted but not required.
- The diskette submission will be accompanied by a statement from the Appointed Actuary certifying that in his or her opinion the assumptions used for these calculations are not unreasonable for the products, scenarios, and regulatory purpose being tested.
- The scenario testing used for this purpose will use the same assumptions as to cash flows, assets associated with tested liabilities, future investment strategy, rate spreads, credit losses, "as-of" date and treatment of negative cash flows as were used for cash flow testing (except that if negative cash flow is modeled by borrowing, the actuary needs to make sure that the amount and cost of borrowing are reasonable for that particular scenario of the C-3 testing) The other differences are the interest scenarios themselves and how the results are used.
- The actuary must also assure that the cash flow testing used for the 50 or 12 scenarios does not double count cash flow offsets to the interest rate risks. That is that the calculations do not reduce $\mathrm{C}-3$ and another RBC component for the same margins. For example, certain reserve margins on some guaranteed separate account products serve an AVR role and are credited against the C-1 requirement. To that degree, these margins should be removed from the reserve used for $\mathrm{C}-3$ testing.
- Sensitivity testing of key assumptions such as lapses is required.


### Next Steps of C3 Phase 1

Although this report is our final recommendation for "Phase I" of our project, at least two areas of unfinished business remain:

a) Review of the Outcomes of this Revised Approach

The C-3 result under this recommendation is limited to between balf and twice the current factors. This was done in part to limit the severity of the impact of the change until the results of this method could be evaluated. Substantial testing of this approach was done for a variety of products and portfolios, but, unlike most of the prior changes to Risk Based Capital, the industry-wide impact of this change couldn't be measured in advance. If the industry-wide results (both statistical and anecdotal) show a distribution of outcomes that seems believable, it may be desirable to widen this range. If the results are puzzling, then we would want to pursue further research to evaluate the outliers.

b) Expansion to Equity Indexed and Variable products

Aside from a guaranteed fixed option within a variable product, these two product groups require modeling beyond the scope of our "Phase I" project, since they also involve behavior of indices or of funds. Expanding the C3 work to encompass these products in a more refined manner than today is appropriate in the future.

## Appendix I - C3 Phase 1 Scenario Testing Methodology
### General Approach

1. Use the same asset and liability model(s) as used for year-end Asset Adequacy Analysis cash flow testing, or a consistent model.
2. Run the scenarios (12 or 50 ) produced from the interest-rate scenario generator. These scenarios come from a randomly generated set of 200 scenarios and were selected because they have the greatest likelihood of producing a $\mathrm{C}-3$ result at least as great as that determined by using all 200 scenarios. The other scenarios can be characterized as more "level" and less volatile than the selected set.
3. The statutory surplus result, $S(t)$, should be captured for every scenario for each calendar year-end of the testing period. The surplus result is equal to statutory assets less statutory liabilities for the portfolio.
4. For each scenario, the $\mathrm{C}-3$ measure is the most negative of the series of present values $\mathrm{S}(\mathrm{t})^{*} \mathrm{pv}(\mathrm{t})$, where $\mathrm{pv}(\mathrm{t})$ is the accumulated discount factor for $t$ years using $105 \%$ of the after-tax one-year Treasury rates for that scenario. In other words:

$$
p v(t)=\prod_{1}^{t} 1 /\left(1+i_{t}\right)
$$

5. Rank the scenario-specific $\mathrm{C}-3$ measures in descending order, that is from the largest need for capital to the smallest. Scenario rank l's measure is the largest amount needed to eliminate the very worst pv result.
6. The final $\mathrm{C}-3$ requirement is calculated as the weighted average of a subset of the ranked scenario specific $\mathrm{C}-3$ results.

a) For the 50 scenario set, the $\mathrm{C}-3$ results are multiplied by the following series of weights:

|Scenario Rank:|17|16|15|14|13|12|11|10|9|8|7|6|5|
|-|-|-|-|-|-|-|-|-|-|-|-|-|-|
|Weight:|.02|.04|.06|.08|.10|.12|.16|.12|.10|.08|.06|.04|.02| 

The sum of these products is the $\mathrm{C}-3$ requirement for this product.

b) For the 12 scenario set, the $\mathrm{C}-3$ requirement is calculated as the average of the $\mathrm{C}-3$ results for the scenarios ranked 2 and 3 , but cannot be less than half the worst scenario result.

7. If multiple asset/liability portfolios are tested and aggregated, the aggregate C-3 requirement can be derived by first summing the $S(t)$ 's from all the portfolios (by scenario) and then following steps 4 through 6 . An alternative method is to calculate the $\mathrm{C}-3$ result by scenario for each product, sum them by scenario, rank-order them, and then apply the above weights. If some products are tested with 12 scenarios and some with 50 , aggregation can only be done within like scenario sets.

### Single Scenario C-3 Measurement Considerations

1. GENERAL METHOD - this approach incorporates interim values, consistent with approach used for bond, mortgage and mortality RBC factor quantification. The approach establishes the risk measure in terms of an absolute level of risk (e.g., solvency) rather than volatility around an expected level of risk. It also recognizes reserve margins, to the degree that such margins haven't been recognized for or used to offset other RBC requirements.
2. INITIAL ASSETS = RESERVES - consistent with Appointed Actuary practice, the asset adequacy cash flow models are run with initial assets equal to reserves; that is, no surplus assets are used.
3. AVR - Although AVR and related assets are usually included in initial assets for Asset Adequacy cash flow testing, they should not be included in the initial assets used in the $\mathrm{C}-3$ modeling. These assets are available for future credit loss deviations over and above expected credit losses. These deviations are covered by C-1 RBC requirements. Similarly, future AVR contributions should not be modeled. However, expected credit losses, which are not covered by C-1, should be modeled.
4. IMR - The IMR reserve, assets, and run-off schedule associated with a category (a) product should be included in that product's cash flow modeling for determination of RBC. If a callable asset is called below carrying value, the IMR modeling should reflect the impact of that loss.
5. INTERIM MEASURE - retained statutory surplus $S(t)$ (i.e., statutory assets less statutory liabilities) is used as the year-to-year interim measure.
6. TESTING HORIZONS - surplus adequacy should be tested over a period that extends to a point at which contributions to surplus on a closed block are immaterial in relationship to the analysis. If some products are being cash flow tested for Asset Adequacy Analysis over a longer period than the 30 years generated by the interest rate scenario generator, the scenario rates should be held constant at the year 30 level for all future years. A consistent testing horizon is required for all lines tested if the $\mathrm{C}-3$ results from different lines of business are to be aggregated.
7. TAX TREATMENT - the tax treatment should be the same as that used forAsset Adequacy Analysis. Disclosure of tax assumptions may be required.
8. REINVESTMENT STRATEGY - the reinvestment strategy should be the same as that used for Asset Adequacy Analysis cash flow testing.
9. DISINVESTMENT STRATEGY - In general, negative cash flows should be handled just as they are in the Asset Adequacy Analysis. The one caveat is that, since the RBC scenarios are more severe, models that depend on borrowing need to be reviewed to be confident that loans in the necessary volume are likely to be available at a rate consistent with the model's assumptions for that scenario. If not, adjustments need to be made.

If negative cash flows are met by selling assets, then appropriate modeling of contributions and withdrawals to the IMR needs to be reflected.

10. STATUTORY PROFITS RETAINED - the measure is based on a profits retained model, anticipating that statutory net income earned one period is retained to support capital requirements in future periods. In other words, no stockholder dividends are assumed to be paid, but policyholder dividends, excess interest, declared rates, etc. are assumed to be paid or credited consistent with company practice.
11. LIABILITY and ASSET ASSUMPTIONS - the liability and asset assumptions should be those used in Asset Adequacy Analysis modeling. Disclosure of these assumptions may be required.
12. SENSITIVITY TESTING - Key assumptions shall be stress tested (e.g. lapses increased by $50 \%$ ) to evaluate sensitivity of the resulting C-3 requirement to the various assumptions made by the actuary. Disclosure of these results may be required.

## Appendix II - Frequently Asked Questions (C3 Phase 1)

1. Where can the scenario generator be found? What is needed to run it?

The scenario generator is a Microsoft Excel spreadsheet. By entering the Treasury yield curve at the date for which the testing is done, it will generate the sets of 50 or 12 interest rate scenarios. It requires Windows 95 or higher. This spreadsheet and the instructions are available on the NAIC website (www.naic.org) or at www.barnert.com. It is also available on diskette from the Academy of Actuaries.

2. The results of the scenario testing may be sensitive information in some instances. How can it be kept confidential?

As provided for in Section 8 of the Risk-Based Capital (RBC) For Insurers Model Act, all information in support of and provided in the RBC Reports (to the extent the information therein is not required to be set forth in a publicly available annual statement schedule) with respect to any domestic or foreign insurer which is filed with the commissioner constitute information that might be damaging to the insurer if made available to its competitors, and therefore shall be kept confidential by the commissioner. This information shall not be made public or be subject to subpoena, other than by the commissioner and then only for the purpose of enforcement actions taken by the commissioner under the RBC For Insurers Model Act or any other provision of the insurance laws of the state.

3. The definition of the annuities category talks about "debt incurred for funding an investment account...". Could you give a specific description of what is intended?

One example is a situation where an insurer is borrowing under an advance agreement with a federal home loan bank, under which agreement collateral, on a current market value basis, is required to be maintained with the bank. This arrangement has many of the characteristics of a GIC, but is classified as debt.

4. The instructions specify that the same assumptions are to be used as for Asset Adequacy Analysis, but my company cash flow tests a combination of Universal Life and annuities for that analysis and using the same assumptions will produce incorrect results. What was intended in this situation?

Where this situation exists, assumptions should be used for the Risk Based Capital work which are consistent with those used for the other testing. In other words, the assumptions used should be appropriate for the annuity component being evaluated for RBC and consistent with the overall assumption set used for Asset Adequacy Analysis.

5. Can a company test other products voluntarily and aggregate the results?

No, only the products identified can be scenario tested and aggregated for RBC.

## Appendix III - Technical Aspects of the Scenario Generator and the Scenario Selection Process

The model used to generate the interest rate scenarios for the C-3 $\mathrm{RBC}$ project is a stochastic variance model with mean reversion. A number of different models and assumptions were examined before this one was chosen. The exact formulas, parameters, and assumptions of the stochastic variance model are given in Section A.

### C3 Phase 1 Scenarios: STOCHASTIC VARIANCE MODEL: DEVELOPMENT AND VALIDATION

The Committee examined and analyzed a number of different models, parameters, and assumptions. The goal was to develop a model which would reproduce as closely as possible certain historical relationships and patterns. We examined minimum and maximum interest rates, the number and length of interest rate inversions, and the absolute and relative distribution of interest rates. The exact statistics which were analyzed, along with the historical and scenario-generated numbers, are given in Section B.

Based on historical data (monthly yields from January, 1951 through December, 1995), it was obvious that neither a normal nor lognormal model could accurately simulate the observed change in interest rates. Interest rate movements had been more "peaked" and "fat-tailed" than that suggested by either distribution, in addition to other shortcomings. As a result, the normal and lognormal distributions were both rejected as potential models, since it was behavior on the tails of the distribution that Risk Based Capital is most focused on.

After a significant amount of experimentation, the Committee finally arrived at an appropriate model, a generalized stochastic variance model with mean reversion. As stated earlier, the exact specifications are in Section A. The initial parameters were derived from a parameter estimation model which applies maximum likelihood estimation techniques to observed, historical data (1951-1995). Four different variables were modeled: the natural log of the long-term ( 20 -year) rate, the natural log of the monthly variance of the long-term rate, the excess of the short-term (1-year) rate over the long-term rate, and the natural log of the monthly variance of the previously defined "excess".

The first attempt at estimating the parameters resulted in long-term rates which reproduced historical patterns very closely. Unfortunately, they did not do a very good job of reproducing the tendencies of short-term rates. In order to correct the problem, we experimented with the parameters and later, re-examined the historical data.

The historical data showed that the absolute difference between the short-term and longterm rate closely resembled a normal distribution. Below is a table showing this result. The table has been "normalized", meaning that the numbers are given in terms of standard deviations away from the mean. The data has a mean of -80 basis points and a standard deviation of 120 basis points.

**C3 Phase 1 Scenarios: ABSOLUTE DIFFERENCE BETWEEN THE SHORT-TERM AND LONG-TERM RATE <br> "NORMALIZED" HISTORICAL DATA**

| Number of Standard Deviations <br> Away From Mean | Number of <br> Observations |
| :---: | :---: |
| 5 | 0 |
| 4 | 1 |
| 3 | 4 |
| 2 | 28 |
| 1 | 132 |
| 0 | 202 |
| -1 | 126 |
| -2 | 32 |
| -3 | 3 |
| -4 | 0 |
| -5 | 0 |

In the above table, " 0 " standard deviations mean an observation is between one-half and negative one-half standard deviations from the mean, " 1 " means an observation is between one-half and 1 and one-half standard deviations from the mean, etc.

Since the absolute difference essentially follows a normal distribution, a constant variance, rather than a stochastic one, was used for modeling this particular term. Based on the historical data, the standard deviation of the change in the difference between the short-term and long-term rate is $0.381 \%$.

The parameter estimation model was rerun using the previously stated changes to determine new equations and parameters. 100 random scenarios were generated and examined. Since the absolute difference (between the short-term and long-term rate) was being modeled, this sometimes resulted in a slightly negative short-term rate. As a fix, any month the short-term rate falls below $0.4 \%$, the historical minimum, it is set at $25 \%$ of the long-term rate. Although this approach is not scientific, it happens very rarely and does not materially effect the overall results of the generator.

With the slight modification just described, 100 new scenarios were created. Once again, long-term rates looked very good. Short-term rates, while closer to historical trends, still had a couple of significant problems. Inversions occurred about $18 \%$ of the time, well above the historical levels of $13.45 \%$. In addition, there were too many times when the short-term rate exceeded the long-term rate by over 300 basis points, a situation which has only occurred once historically.

After more experimentation, the problems were solved by strengthening the effect of the mean reversion term (in the formula generating the excess of the short-term over the long-term rate). The factor was increased from its derived level of 0.022 to 0.042 . None of the other parameters or formulas were altered. (These are the equations in Section A.)

With the new mean reversion term, results were achieved which were excellent in many areas and reasonable in the others. Long-term rates looked very good, as always. The occurrence of an inversion was reduced to $14.09 \%$ of the time, compared to the historical level of $13.45 \%$. In addition, there were only 62 months, out of a possible 36,000 , when the short-term rate exceeded the long-term rate by over 300 basis points $(0.17 \%$ of the time). This corresponds closely to reality, since it has only happened once in the 528month period studied, or $0.19 \%$ of the time.

Section $\mathrm{B}$ has a series of tables which summarize the generated scenarios, and compares them to their historical (1951-1995) averages. The first table shows, in broad categories, the distribution of the long-term rate and the difference between the short and long-term rate on an absolute (non-normalized) basis. The second table shows, on a normalized basis (as previously defined), the distribution of the change in the long-term rate and the distribution of the short-term minus the long-term rate. The final table shows the historical and generated distribution of interest rate inversions. For all tables, the historical numbers have been increased proportionately so that the number of historical observations and the number of generated observations are equal.

It should also be noted that the statistics in Section B are at least a little dependent on the starting yield curve. In particular, a significantly different starting point could noticeably impact the non-normalized distribution of long-term rates. However, its impact on the other statistics would be minimal. It does not change any of the conclusions reached about the validity of the stochastic variance model.

The yield curve on which the statistics are based is given below:

TREASURY YIELD CURVE AS OF 9-30-96

3-Month: $5.14 \%$

6-Month: $5.37 \%$

1-Year: $5.71 \%$

2-Year: $6.10 \%$
3-Year: $6.28 \%$

5 -Year: $6.46 \%$

7-Year: $6.60 \%$
10-Year: $6.72 \%$

20-Year: $7.05 \%$

30 -Year: $6.93 \%$

### C3 Phase 1 Scenarios: DERIVATION OF THE TREASURY YIELD CURVE

After the 1-year (short-term) and 20-year (long-term) coupon rates have been generated, the remainder of the treasury yield curve is derived from various interpolation and iterative formulas. First the 3-month treasury is calculated as a linear function of the 1year and 20 -year rates. The equation (given in Section C) comes from a linear regression performed on the monthly treasury coupon rates covering the period from March, 1977 through May, 1997.

The 3-month and 20-year coupon rates serve as the starting point for calculating the other treasury rates (6-month, 1-year, 2-year, 3-year, 5 -year, 7 -year, 10 -year, and 30 -year). We decided to interpolate using forward rates rather than coupon rates, in order to prevent unintended and in some cases, unrealistic results.

The first thing that was done was convert the historical coupon-paying yield curves into historical forward curves. Since our data was limited to 10 points along the yield curve (listed above), forward rates were only calculated at the same 10 points. The key assumption used in calculating the historical forwards is that forward rates remain constant in between maturities. For example, the 21 -year, 22 -year,..., and 29 -year forward rates are all assumed equal to the 20 -year forward. This is different than PTS, which uses linear interpolation to get at rates between maturities.

Linear regressions were performed on the calculated forward rates. Each forward rate was represented as a linear function of the 3-month and 20-year forward. (The regression equations are given in Section C.) Initially the 30-year forward was a linear function of the 3-month and 20 -year forwards, just like the other rates. Unfortunately, the 30-year regression equation produced very unrealistic results, so the simplifying assumption was made to set the 30 -year forward equal to the 20 -year forward.

Given the interpolation formulas and the generated 3-month and 20-year coupon rates, the remainder of the coupon yield curve is derived using an iterative process. The first step is to set the 3-month forward rate equal to the 3-month coupon rate. A first estimate of the 20 -year forward is then made. Given the 3 -month and 20 -year forwards, the other forward rates are calculated using the regression equations in Section C. Once the forward curve has been generated, it is used to derive the corresponding coupon-paying curve. If the derived 20 -year coupon rate equals the previously generated 20 -year coupon rate, we have a "legitimate" treasury yield curve and the process stops. Otherwise, another estimate of the 20 -year forward is made using a Newton-Raphson process, and the iterations continue until the 20 -year derived rate is equal to the 20 -year generated rate. This process is done for every year in which random interest rates are generated.

Underlying the entire process is the random number generator, which has been taken directly from the book "Numetical Recipes in C/. For a given initial seed, the generator always produces the identical series of random numbers in identical order. This means that the random characteristics of the generated scenarios will be the same whatever the initial yield curve. The characteristics of a scenario refers to the level of interest rates (high or low interest rate environment), and the shape of the yield curve (increasing, flat, or inverted).

## Appendix III - Section A
### Interest Rate Generator for C-3 Project

The generator contains three variables which vary over time, plus one constant:

$\phi_{t} \quad$ The natural log of the long term interest rate at time $t$.

$\varphi_{t} \quad$ The excess of the short term rate over the long term rate at time $t$.

$\theta_{t}$ The natural $\log$ of the monthly variance of $\phi_{t}$.

$\vartheta_{t}$ The natural log of the monthly variance of $\varphi_{t}$ (the constant).

Each of these variables (except $\vartheta_{t}$ ) will be assumed to follow a mean reverting random process. $\phi_{t}$ and $\varphi_{t}$ will be modeled with monthly time steps, while $\theta_{t}$ will be modeled with an annual time step. $\vartheta_{t}$ is assumed to be constant.

The following equations govern the evolution of $\theta_{t}$ and $\vartheta_{t}$ :

$$
\begin{aligned}
& \theta_{t+1}=\theta_{t}-2.40-.347 \theta_{t}+.59 \varpi_{t}^{\theta} \\
& \vartheta_{t}=\ln \left((0.0038091)^{2}\right) \quad(0.381 \%=\text { the average historical monthly } \\
& \quad \text { volatility from } 1951-1995)
\end{aligned}
$$

$16 \%=$ the assumed correlation between the natural log of the long term interest rate, and the excess of the short rate over the long rate

where $\bar{\sigma}_{t}^{\theta}$ is an independent random variable with unit variance distributed according to a normal distribution.

In the following formulas for $\phi_{t}$ and $\varphi_{t}$ assume that $\theta_{t}$ and $\vartheta_{t}$ for $t$ between $n$ and $n+1$ are equal to their respective values at $n$.

$$
\begin{aligned}
& \phi_{t+\frac{1}{12}}=\phi_{t}-.0048\left(\phi_{t}-\ln (.0655)\right)+.210\left(\varphi_{t}+.0105\right)+e^{\frac{\theta_{t}}{2}} \varpi_{t}^{\phi} \\
& \varphi_{t+\frac{1}{12}}=\varphi_{t}-.042\left(\varphi_{t}+.0105\right)-.00024\left(\phi_{t}-\ln (.0655)\right)+e^{\frac{\vartheta_{t}}{2}}\left(.16 \varpi_{t}^{\phi}+\sqrt{1-.16^{2}} \varpi_{t}^{\phi}\right)
\end{aligned}
$$

where $\varpi_{t}^{\phi}$ and $\varpi_{t}^{\varphi}$ are independent standard random normal variables.

## C3 Phase 1 Scenario Appendix III - Section B 
### TABLE 1: NON-NORMALIZED (ABSOLUTE) RATES

1a. Distribution of the Long-Term Rate

| Count |  |  |
| :---: | :---: | :---: |
| Rate | Historical | Generated |
| $>16 \%$ | 0 | 220 |
| $14 \%-16 \%$ | 340 | 294 |
| $12 \%-14 \%$ | 1976 | 702 |
| $10 \%-12 \%$ | 2724 | 2037 |
| $8 \%-10 \%$ | 7084 | 4960 |
| $6 \%-8 \%$ | 8379 | 13,144 |
| $<6 \%$ | 15,396 | 14,543 |

**LONG-TERM STATISTICS**

|  | Historical | Generated |
| :--- | ---: | ---: |
| Minimum: | $2.53 \%$ | $1.30 \%$ |
| Maximum: | $15.38 \%$ | $20.32 \%$ |
| Average: | $6.73 \%$ | $6.76 \%$ |

**1b. Distribution of (Short-Term Rate) - (Long-Term Rate), in Basis Points**

Count

| $\frac{\text { Difference }}{>400}$ | Historical | Generated |
| :---: | :---: | :---: |
| $300-400$ | 0 | 7 |
| $200-300$ | 67 | 55 |
| $100-200$ | 466 | 307 |
| $0-100$ | 1666 | 1747 |
| $(-100)-0$ | 6466 | 5296 |
| $(-200)-(-100)$ | 12,467 | 9238 |
| $(-300)-(-200)$ | 9733 | 10,518 |
| $(-400)-(-300)$ | 3733 | 6441 |
| $<(-400)$ | 1334 | 1999 |
|  | 67 | 392 |

**SHORT-TERM MINUS LONG-TERM STATISTICS (IN BASIS POINTS)**

|  | Historical |  Generated |
| :--- | :---: | :---: | 
| Minimum: | -423 | -564 |
| Maximum: | 368 | 477  |
| Average: | -80 | -109 |

## C3 Phase 1 Scenario Appendix III - Section B 
### TABLE 2: "NORMALIZED" STATISTICS

**CHANGE IN LONG-TERM RATE (SHORT) MINUS (LONG)**

| Number of Standard | Count |  | Count |  |
| :---: | :---: | :---: | :---: | :---: |
|  | Historical | Generated | Historical | Generated |
| Deviations |  |  |  |  |
| 5 | 0 | 38 | 0 | 0 |
| 4 | 68 | 100 | 68 | 24 |
| 3 | 341 | 343 | 273 | 239 |
| 2 | 1635 | 1704 | 1909 | 2259 |
| 1 | 7153 | 7449 | 9000 | 8434 |
| 0 | 17,235 | 16,270 | 13,773 | 13,683 |
| -1 | 7153 | 7980 | 8591 | 9166 |
| -2 | 1771 | 1651 | 2182 | 2035 |
| -3 | 477 | 290 | 205 | 160 |
| -4 | 68 | 54 | 0 | 0 |
| -5 | 0 | 21 | 0 | 0 |

TABLE 3: LENGTH AND SEVERITY OF INTEREST RATE INVERSIONS

|  |  | Count |  |
| :---: | :---: | :---: | :---: |
| Length of Inversion In |  | Historical |  |
| Months |  |  |  |
| $0-6$ | 476 | 363 |  |
| $6-12$ | 204 | 75 |  |
| $12-24$ | 68 | 29 |  |
| $24-36$ | 0 | 17 |  |
| $36-48$ | 0 | 7 |  |

Note: The number of times there is an inversion differs between the historical and generated scenarios by a significant amount. There are 748 historical inversions, increased proportionately for 100 monthly scenarios, compared to 576 generated ones. However, the number of months an inversion exists is very close to historical --- $14.09 \%$ of the time compared to $13.45 \%$ (historical).

## Appendix III - Section C

**1. INITIAL COUPON AND FORWARD RATES**

3-Month Coupon $=1.1785 *(1-$ Year Coupon $)-0.2616 *(20$-Year Coupon $)+0.0045$

3-Month Forward $=3$-Month Coupon

**2. FORWARD RATE INTERPOLATION FORMULAS**

|  | $<\cdots$ Regression Co-Efficients $\cdots \cdots>>$ |  |  |
| :---: | :---: | :---: | :---: |
| Forward Rate | 3-Month Forward | 20-Year Forward | Constant |
| 6-Month | 0.99276 | 0.11358 | -0.00436 |
| 1-Year | 0.86814 | 0.19985 | -0.00316 |
| 2-Year | 0.62614 | 0.48208 | -0.00649 |
| 3-Year | 0.55221 | 0.51409 | -0.00415 |
| 5-Year | 0.40933 | 0.62311 | -0.00003 |
| 7-Year | 0.32122 | 0.68682 | 0.00320 |
| 10-Year | 0.30691 | 0.60731 | 0.01102 |

30-Year Forward $=20$-Year Forward

## Appendix IV - AAA C-3 Pilot Testing: Selecting the 50 \&12 Scenario Subsets

Cash flow testing models developed in support of year-end 1996 Appointed Actuary efforts were used to evaluate the new C-3 approach on a pilot basis. Models for six blocks of in-force liabilities were tested for the following product types:

- Guaranteed Investment Contracts
- Single Premium Immediate Annuities
- Single Premium Deferred Annuities
- Flexible Premium Deferred Annuities
- Group Pensions - Reg. 128-Payable Annuities
- Group Pension - IPG/Defined Benefit

Par Life insurance was also modeled, but didn't generate a C-3 requirement, so it was not used in selecting scenario sets.

To evaluate whether the RBC measurement methodology was appropriately sensitive to alternative asset strategies (including some extreme ones), the liability portfolios were run using a set of eight stylized investment strategies below. Besides strategies that would be considered to be well managed, the set includes portfolios with exposures to duration mismatch and portfolios with exposures to call-option risk.

- Non-callable A-rated Bonds - bullet (liability duration-matched)
- Non-callable A-rated Bonds - ladder (liability duration-matched)
- Non-callable A-rated Bonds - extreme bar-bell (liability duration-matched)
- Non-callable A-rated Bonds - ladder (asset duration greater than liability by three years)
- Non-callable A-rated Bonds - ladder (asset duration less than liability by two years)
- Residential Mortgage Pass-Thrus (liability duration-matched - approximate)
- CMOs: PAC tranche (liability duration-matched - approximate)
- CMOs: support tranche (liability duration-matched - approximate)

The pilot testing consisted of running each of the 48 product type / stylized asset strategy combinations (48 Combinations) using the set of all interest rate scenarios. For each of the 48 Combinations, the accumulated statutory position was derived and captured for each calendar year over the testing horizon for all 200 scenarios.

### Selection of the Scenarios and the Optimal Number

The results from each of the 48 Combinations using the full 200 scenario set were collected in a common database. Empirical analyses were performed to select a subset of the 200 scenarios such that this subset closely approximated the C-3 factors derived from the full 200 -scenario set across the 48 Combinations.

In the end, 50 scenarios were selected. These scenarios can be thought of producing a C3 factor result across a wide array of product/asset strategy combinations consistent with the larger 200-scenario set. Alternatively, the $150(75 \%)$ scenarios not selected can be characterized as those not likely to generate a C-3 factor, and are generally more "level" and less volatile than the 50 selected. Thus, the formula used to derive the $\mathrm{C}-3$ factor from the subset of 50 assumes that they come from a larger set of 200 , and that testing the other 150 scenarios would not provide any material additional information adding little value relative to the extra effort.

### Selecting the Subset of 50

- For each of the 48 Product (6) \& Asset Strategy (8) combinations, an "actual" C-3 factor was developed using the full set of 200 scenarios. The C-3 factor for each of the 48 Product/Asset combinations was calculated by ordering the 200 scenarios from worst-to-best using minimum surplus (a weighted average of the factors between the $92^{\text {nd }}$ percentile and the $98^{\text {th }}$ percentile, centered at the $95^{\text {th }}$ percentile, and including $1 / 2$ percentiles) as the criteria. Of the 200 scenarios, 83 of them contributed to at least one of the 48 combination's weighted-average $\mathrm{C}-3$ factors.
- Assigning an ordinal number to the sorted (worst-to-best) scenarios within each of the 48 combinations, a rank for each scenario across all combinations was determined. Sorting by rank, the 50 most frequent contributors to the calculation of all weightedaverage $\mathrm{C}-3$ factors were identified and an ordered, weighted-average $\mathrm{C}-3$ factor was calculated for each of the 48 combinations.
- The set of "50 worst" closely reproduces the "actual" weighted-average C-3 factor for most of the 48 Combinations. The exceptions in terms of absolute C-3 factor difference were: GIC Ladder-2, SPIA Barbell, SPIA Ladder+3, SPIA CMO-Support and FPDA Barbell. These differences were deemed reasonable given that these few combinations had very high C-3 factors to start with, and thus the differences were not considered problematic.
- In the same way, 20, 30 and 40 scenario subsets were selected and tested. Compared to the 50 -scenario set, there is a significant loss of "precision" that occurs when the number of scenarios is limited to 20 or 30 scenarios. The deterioration was less going from 50 to 40 scenarios, but still enough that a 50 scenario subset was deemed to be a more appropriate subset for $\mathrm{C}-3$ testing. (See Attachment X).


### Selecting the Subset of 12

After selecting the 50-scenario subset, additional empirical studies were conducted to determine if a yet smaller subset ( $10-20$ scenarios) could be chosen from the 50 such that a C-3 factor result would be at least as conservative as using the 50-scenario subset. The objective was to pick a subset of the 50 such that the single worst (highest) C-3 factor of the subset was at least as great as the $\mathrm{C}-3$ factor derived from the full 200 set. Thus, if a
company were to use this limited subset, their work effort might be reduced with the likelihood of a more conservative C-3 factor.

Using a trial and error approach, a set of 12 scenarios was selected that met the objective. The analysis indicated the single worst result of the 12 scenarios produced an overly conservative C-3 factor. After some experimentation, an approach was selected that provided a more reasonable result: the average of the second worst and third worst C-3 factor, but not less than one-half the single worst factor from the subset. For the sample 48 Combinations, using the 12 scenarios and the formula approach just described produced C-3 factors 1.5 to 2.5 times the full 200 -scenario factor, averaging about 1.8 times.

Two product/strategy combinations were merged to study the effects of aggregation. For both the 50 -scenario subset and the 12 -scenario subset, these studies yielded results that were consistent with the expected benefits of aggregation. The results for the 12-scenario subset were also consistent with the level of conservatism found in the non-aggregated 48 Combinations. This latter result provided further assurance that using the 12-scenario subset would generate a more conservative result than the 50-scenario subset.

Attachment $Y$ provides a pictorial perspective of the five-year rates across 30 years for the 12-scenario subset.

Attachment $Z$ provides some statistics related the 200 -scenario set. The first page of the attachment contains the 50 scenarios selected to be used for $\mathrm{C}-3$ testing. The first 12 (shaded) are the subset of the 50 that can be used in the abbreviated testing. Not unexpectedly, the scenario statistic "scenario description" over the first 10 years has very few "levels" in the 50 and none in the 12. These "levels" are very prevalent in the 150 scenarios not selected. This is consistent with the notion that more " $\mathrm{C}-3$ " information is contained in the non-level scenarios.

